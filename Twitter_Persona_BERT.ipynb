{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT \n",
    "https://colab.research.google.com/drive/1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU#scrollTo=E_t4cM6KLc98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# * File:    Twitter_Persona_GloVe.py\n",
    "# *\n",
    "# * Author1:  Pavan Kumar K N (pavankumar.karkekopp@ucalgary.ca)\n",
    "# * Date:     11th Aug 2019\n",
    "# * Summary of File:\n",
    "# * Explore mbti_1.csv file acquired from https://www.kaggle.com/datasnaek/mbti-type\n",
    "# * Apply state-of-the-art reported publicly\n",
    "# * Build classifier model that is better using machine learning techniques\n",
    "\n",
    "#Just making sure the right environment is running this script\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# # Load pre-trained model tokenizer (vocabulary)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Read Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_types(row):\n",
    "    t=row['type']\n",
    "\n",
    "    I = 0\n",
    "    N = 0\n",
    "    T = 0\n",
    "    J = 0\n",
    "    \n",
    "    if t[0] == 'I': I = 1\n",
    "    elif t[0] == 'E': I = 0\n",
    "    else: print('Could not identify label for I-E')\n",
    "        \n",
    "    if t[1] == 'N': N = 1\n",
    "    elif t[1] == 'S': N = 0\n",
    "    else: print('Could not identify label for N-S')\n",
    "        \n",
    "    if t[2] == 'T': T = 1\n",
    "    elif t[2] == 'F': T = 0\n",
    "    else: print('Could not identify label for T-F')\n",
    "        \n",
    "    if t[3] == 'J': J = 1\n",
    "    elif t[3] == 'P': J = 0\n",
    "    else: print('Could not identify label for J-P')\n",
    "    return pd.Series( {'IE':I, 'NS':N , 'TF': T, 'JP': J }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to binarize the types into simple lists instead of pandas.series\n",
    "personality_binary = {'I':1, 'E':0, 'N':1,'S':0, 'T':1, 'F':0, 'J':1, 'P': 0}\n",
    "binary_personality = [{1:'I', 0:'E'}, \n",
    "                      {1:'N', 0:'S'},\n",
    "                      {1:'T', 0:'F'},\n",
    "                      {1:'J', 0:'P'}]\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    return [personality_binary[l] for l in personality]\n",
    "\n",
    "\n",
    "def translate_binary(personality):\n",
    "    # transform binary vector to mbti personality\n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += binary_personality[i][l]\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseMBTI(mbti_file_path): \n",
    "    \n",
    "    \n",
    "    #List of strings to remove from the corpus\n",
    "    unique_type_list = ['INFJ', \n",
    "                        'ENTP', \n",
    "                        'INTP', \n",
    "                        'INTJ', \n",
    "                        'ENTJ', \n",
    "                        'ENFJ', \n",
    "                        'INFP', \n",
    "                        'ENFP',\n",
    "                        'ISFP', \n",
    "                        'ISTP', \n",
    "                        'ISFJ', \n",
    "                        'ISTJ', \n",
    "                        'ESTP', \n",
    "                        'ESFP', \n",
    "                        'ESTJ', \n",
    "                        'ESFJ']\n",
    "    list_personality = []\n",
    "    list_posts = []\n",
    "    \n",
    "\n",
    "    \n",
    "    # Initialize for Lemmatization\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "    #List of unique types of personality\n",
    "    unique_type_list = [x.lower() for x in unique_type_list]\n",
    "\n",
    "    #Read file\n",
    "    mbti_data = pd.read_csv(mbti_file_path)\n",
    "\n",
    "\n",
    "    raw_posts = mbti_data.posts.values\n",
    "    filtered_posts = [p.split(\"|||\") for p in raw_posts]\n",
    "    mbti_data_encoded = mbti_data.join(mbti_data.apply(lambda row: encode_types(row), axis=1))\n",
    "    \n",
    "    len_data = len(mbti_data_encoded)\n",
    "    i=0\n",
    "    \n",
    "    \n",
    "    for row in mbti_data_encoded.iterrows():\n",
    "        i+=1\n",
    "        tweets = []\n",
    "\n",
    "        if (i % 500 == 0 or i == 1 or i == len_data):\n",
    "            print(\"%s of %s rows\" % (i, len_data))\n",
    "\n",
    "        ##### Remove and clean comments\n",
    "        posts = row[1].posts\n",
    "        \n",
    "        for tweet_string in posts.split(\"|||\"):\n",
    "            #Removing mentions\n",
    "            tweet_string = tweet_string.replace('@username', '')\n",
    "            #Removing unecessary spaces\n",
    "\n",
    "            #Removing URL\n",
    "            tweet_string = re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", tweet_string)\n",
    "            tweet_string = tweet_string.strip()\n",
    "            tweets.append(tweet_string)\n",
    "\n",
    "        j=0\n",
    "        for pos in tweets:\n",
    "            if pos is not None:\n",
    "                pos = re.sub(\"[^a-zA-Z]\", \" \", pos)\n",
    "                pos = re.sub(\" +\", \" \", pos).lower()\n",
    "                pos = \" \".join([lemmatiser.lemmatize(w) for w in pos.split(' ')])\n",
    "\n",
    "                if pos!= \" \":\n",
    "                    tweets[j] = pos\n",
    "                else:\n",
    "                    tweets[j] = None\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        tweets = list(filter(None, tweets))\n",
    "\n",
    "        #'Add [SEP] tokens for BERT tokenizer'\n",
    "        processed_tweets = '[SEP]'.join(tweets)\n",
    "        list_posts.append(processed_tweets)\n",
    "        list_personality.append(translate_personality(row[1].type))\n",
    "    return np.array(list_posts), np.array(list_personality)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
    "#         temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
    "#         temp = re.sub(' +', ' ', temp).strip().lower()\n",
    "#         if remove_stop_words:\n",
    "#             temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in stopwords.words(\"english\")])\n",
    "#         else:\n",
    "#             temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n",
    "            \n",
    "#         if remove_mbti_profiles:\n",
    "#             for t in unique_type_list:\n",
    "#                 temp = temp.replace(t,\"\")\n",
    "\n",
    "#         type_labelized = translate_personality(row[1].type)\n",
    "#         list_personality.append(type_labelized)\n",
    "#         list_posts.append(temp)\n",
    "\n",
    "#     list_posts = np.array(list_posts)\n",
    "#     list_personality = np.array(list_personality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 8675 rows\n",
      "500 of 8675 rows\n",
      "1000 of 8675 rows\n",
      "1500 of 8675 rows\n",
      "2000 of 8675 rows\n",
      "2500 of 8675 rows\n",
      "3000 of 8675 rows\n",
      "3500 of 8675 rows\n",
      "4000 of 8675 rows\n",
      "4500 of 8675 rows\n",
      "5000 of 8675 rows\n",
      "5500 of 8675 rows\n",
      "6000 of 8675 rows\n",
      "6500 of 8675 rows\n",
      "7000 of 8675 rows\n",
      "7500 of 8675 rows\n",
      "8000 of 8675 rows\n",
      "8500 of 8675 rows\n",
      "8675 of 8675 rows\n"
     ]
    }
   ],
   "source": [
    "list_posts, list_personality = parseMBTI(\"data/mbti_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('enfp and intj moment sportscenter not top ten play prank[SEP]what ha been the most life changing experience in your life [SEP]on repeat for most of today [SEP]may the perc experience immerse you [SEP]the last thing my infj friend posted on his facebook before committing suicide the next day rest in peace [SEP]hello enfj sorry to hear of your distress it s only natural for a relationship to not be perfection all the time in every moment of existence try to figure the hard time a time of growth a [SEP]welcome and stuff [SEP]game set match [SEP]prozac wellbrutin at least thirty minute of moving your leg and i don t mean moving them while sitting in your same desk chair weed in moderation maybe try edible a a healthier alternative [SEP]basically come up with three item you ve determined that each type or whichever type you want to do would more than likely use given each type cognitive function and whatnot when left by [SEP]all thing in moderation sims is indeed a video game and a good one at that note a good one at that is somewhat subjective in that i am not completely promoting the death of any given sim [SEP]dear enfp what were your favorite video game growing up and what are your now current favorite video game cool [SEP]it appears to be too late sad [SEP]there s someone out there for everyone [SEP]wait i thought confidence wa a good thing [SEP]i just cherish the time of solitude b c i revel within my inner world more whereas most other time i d be workin just enjoy the me time while you can don t worry people will always be around to [SEP]yo entp lady if you re into a complimentary personality well hey [SEP] when your main social outlet is xbox live conversation and even then you verbally fatigue quickly [SEP]i really dig the part from to [SEP]banned because this thread requires it of me [SEP]get high in backyard roast and eat marshmellows in backyard while conversing over something intellectual followed by massage and kiss [SEP]banned for too many b s in that sentence how could you think of the b [SEP]banned for watching movie in the corner with the dunce [SEP]banned because health class clearly taught you nothing about peer pressure [SEP]banned for a whole host of reason [SEP] two baby deer on left and right munching on a beetle in the middle using their own blood two caveman diary today s latest happening on their designated cave diary wall i see it a [SEP]a pokemon world an infj society everyone becomes an optimist[SEP]not all artist are artist because they draw it s the idea that count in forming something of your own like a signature [SEP]welcome to the robot rank person who downed my self esteem cuz i m not an avid signature artist like herself proud [SEP]banned for taking all the room under my bed ya gotta learn to share with the roach [SEP]banned for being too much of a thundering grumbling kind of storm yep [SEP]ahh old high school music i haven t heard in age [SEP]i failed a public speaking class a few year ago and i ve sort of learned what i could do better were i to be in that position again a big part of my failure wa just overloading myself with too [SEP]i like this person s mentality he s a confirmed intj by the way [SEP]move to the denver area and start a new life for myself ',\n",
       " array([1, 1, 0, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_posts[0], list_personality[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "bert_model.eval()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 8675 rows\n",
      "100 of 8675 rows\n",
      "200 of 8675 rows\n",
      "300 of 8675 rows\n",
      "400 of 8675 rows\n",
      "500 of 8675 rows\n",
      "600 of 8675 rows\n",
      "700 of 8675 rows\n",
      "800 of 8675 rows\n",
      "900 of 8675 rows\n",
      "1000 of 8675 rows\n",
      "1100 of 8675 rows\n",
      "1200 of 8675 rows\n",
      "1300 of 8675 rows\n",
      "1400 of 8675 rows\n",
      "1500 of 8675 rows\n",
      "1600 of 8675 rows\n",
      "1700 of 8675 rows\n",
      "1800 of 8675 rows\n",
      "1900 of 8675 rows\n",
      "2000 of 8675 rows\n",
      "2100 of 8675 rows\n",
      "2200 of 8675 rows\n",
      "2300 of 8675 rows\n",
      "2400 of 8675 rows\n",
      "2500 of 8675 rows\n",
      "2600 of 8675 rows\n",
      "2700 of 8675 rows\n",
      "2800 of 8675 rows\n",
      "2900 of 8675 rows\n",
      "3000 of 8675 rows\n",
      "3100 of 8675 rows\n",
      "3200 of 8675 rows\n",
      "3300 of 8675 rows\n",
      "3400 of 8675 rows\n",
      "3500 of 8675 rows\n",
      "3600 of 8675 rows\n",
      "3700 of 8675 rows\n",
      "3800 of 8675 rows\n",
      "3900 of 8675 rows\n",
      "4000 of 8675 rows\n",
      "4100 of 8675 rows\n",
      "4200 of 8675 rows\n",
      "4300 of 8675 rows\n",
      "4400 of 8675 rows\n",
      "4500 of 8675 rows\n",
      "4600 of 8675 rows\n",
      "4700 of 8675 rows\n",
      "4800 of 8675 rows\n",
      "4900 of 8675 rows\n",
      "5000 of 8675 rows\n",
      "5100 of 8675 rows\n",
      "5200 of 8675 rows\n",
      "5300 of 8675 rows\n",
      "5400 of 8675 rows\n",
      "5500 of 8675 rows\n",
      "5600 of 8675 rows\n",
      "5700 of 8675 rows\n",
      "5800 of 8675 rows\n",
      "5900 of 8675 rows\n",
      "6000 of 8675 rows\n",
      "6100 of 8675 rows\n",
      "6200 of 8675 rows\n",
      "6300 of 8675 rows\n",
      "6400 of 8675 rows\n",
      "6500 of 8675 rows\n",
      "6600 of 8675 rows\n",
      "6700 of 8675 rows\n",
      "6800 of 8675 rows\n",
      "6900 of 8675 rows\n",
      "7000 of 8675 rows\n",
      "7100 of 8675 rows\n",
      "7200 of 8675 rows\n",
      "7300 of 8675 rows\n",
      "7400 of 8675 rows\n",
      "7500 of 8675 rows\n",
      "7600 of 8675 rows\n",
      "7700 of 8675 rows\n",
      "7800 of 8675 rows\n",
      "7900 of 8675 rows\n",
      "8000 of 8675 rows\n",
      "8100 of 8675 rows\n",
      "8200 of 8675 rows\n",
      "8300 of 8675 rows\n",
      "8400 of 8675 rows\n",
      "8500 of 8675 rows\n",
      "8600 of 8675 rows\n",
      "8675 of 8675 rows\n"
     ]
    }
   ],
   "source": [
    "#Specify max_token_length according to above\n",
    "max_token_length = 256\n",
    "list_posts_vec = []\n",
    "list_personality_vec = []\n",
    "list_posts_len = len(list_posts)\n",
    "\n",
    "count_progress = 0\n",
    "for posts, personality in zip(list_posts, list_personality):\n",
    "    \n",
    "    count_progress += 1\n",
    "    sentence_list = posts.split('[SEP]')\n",
    "    running_token_len = 0\n",
    "    sentence_count = 0\n",
    "    tweet_stream_vec_list = []\n",
    "    text_batch_list = []\n",
    "    text = \"\"\n",
    "    \n",
    "    if (count_progress % 100 == 0 or count_progress == 1 or count_progress == list_posts_len):\n",
    "            print(\"{} of {} rows\".format(count_progress, list_posts_len))\n",
    "            \n",
    "    #Split the sequence of tweets into separate batches of max_token_length\n",
    "    for sentence in sentence_list:\n",
    "        \n",
    "        sentence_len = len(sentence.strip().split(' '))\n",
    "#         print(\" \\Sentence Length: {}\\n  \\nRunning Token Length: {}\".format(sentence_len, running_token_len))\n",
    "        #Case 1: Sentence is smaller than max token_length\n",
    "        if(sentence_len <= max_token_length):\n",
    "           \n",
    "           #Concatenate into single post\n",
    "            if(running_token_len + sentence_len < max_token_length):\n",
    "                running_token_len += sentence_len\n",
    "                text += sentence\n",
    "            \n",
    "            else:\n",
    "                if text!= \"\":\n",
    "                    text_batch_list.append(text)\n",
    "                sentence_count += 1\n",
    "                running_token_len = sentence_len\n",
    "                text = sentence\n",
    "           \n",
    "        \n",
    "        else:\n",
    "            if text!= \"\":\n",
    "                text_batch_list.append(text)\n",
    "            text_len = len(sentence.strip().split(' '))\n",
    "            \n",
    "            while(text_len > max_token_length):\n",
    "                text_batch_list.append( \" \".join(sentence.strip().split(' ')[:max_token_length]))\n",
    "                sentence = \" \".join(sentence.strip().split(' ')[max_token_length:])\n",
    "                text_len = len(sentence.strip().split(' '))\n",
    "            \n",
    "            running_token_len = sentence_len\n",
    "            text = sentence\n",
    "        \n",
    "#     print(\"Total batches: {}\\n{}\".format(len(text_batch_list), [len(text.strip().split(' ')) for text in text_batch_list]))\n",
    "\n",
    "    #Process the batches\n",
    "    for text in text_batch_list:\n",
    "        marked_text = \"[CLS]\" + text + \"[SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#         print(marked_text)\n",
    "#         print((tokenized_text))\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        \n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        \n",
    "#         print(tokens_tensor.shape, segments_tensors.shape)\n",
    "        # Predict hidden states features for each layer\n",
    "        with torch.no_grad():\n",
    "            encoded_layers, _ = bert_model(tokens_tensor, segments_tensors)\n",
    "            \n",
    "        token_embeddings = [] \n",
    "\n",
    "        batch_i = 0 #Since we have only one sentence\n",
    "        # For each token in the sentence...\n",
    "        for token_i in range(len(tokenized_text)):\n",
    "\n",
    "            # Holds 12 layers of hidden states for each token \n",
    "            hidden_layers = [] \n",
    "\n",
    "            # For each of the 12 layers...\n",
    "            for layer_i in range(len(encoded_layers)):\n",
    "\n",
    "                # Lookup the vector for `token_i` in `layer_i`\n",
    "                vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "                hidden_layers.append(vec)\n",
    "\n",
    "        token_embeddings.append(hidden_layers)\n",
    "\n",
    "        # Stores the token vectors, with shape [22 x 768]\n",
    "        token_vecs_sum = []\n",
    "\n",
    "        # For each token in the sentence...\n",
    "        for token in token_embeddings:\n",
    "            # Sum the vectors from the last four layers.\n",
    "            sum_vec = torch.sum(torch.stack(token)[-4:], 0)\n",
    "\n",
    "            # Use `sum_vec` to represent `token`.\n",
    "            token_vecs_sum.append(sum_vec)\n",
    "        \n",
    "        sentence_embedding = torch.mean(encoded_layers[11], 1)\n",
    "        tweet_stream_vec_list.append(sentence_embedding)\n",
    "        \n",
    "    #Concatenate the stream vector into one vector to represent the whole stream\n",
    "    if(len(tweet_stream_vec_list) > 0):\n",
    "        tweet_stream_vec = torch.mean(torch.stack(tweet_stream_vec_list), dim=0)\n",
    "        list_posts_vec.append(tweet_stream_vec.numpy().ravel())\n",
    "        list_personality_vec.append(personality)\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8634, 768), (8634, 4))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list_posts_vec).shape, np.array(list_personality_vec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(list_posts_vec), np.array(list_personality_vec), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred - y)**2))\n",
    "\n",
    "def deep_model(model, X_train, y_train, X_valid, y_valid):\n",
    "    '''\n",
    "    Function to train a multi-class model. The number of epochs and \n",
    "    batch_size are set by the constants at the top of the\n",
    "    notebook. \n",
    "    \n",
    "    Parameters:\n",
    "        model : model with the chosen architecture\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_valid : validation features\n",
    "        Y_valid : validation target\n",
    "    Output:\n",
    "        model training history\n",
    "    '''\n",
    "    model.compile(optimizer='rmsprop'\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train\n",
    "                       , y_train\n",
    "                       , epochs=NB_START_EPOCHS\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       , verbose=1)\n",
    "    return history\n",
    "\n",
    "\n",
    "def eval_metric(history, metric_name):\n",
    "    '''\n",
    "    Function to evaluate a trained model on a chosen metric. \n",
    "    Training and validation metric are plotted in a\n",
    "    line chart for each epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        history : model training history\n",
    "        metric_name : loss or accuracy\n",
    "    Output:\n",
    "        line chart with epochs of x-axis and metric on\n",
    "        y-axis\n",
    "    '''\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name]\n",
    "\n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n",
    "    '''\n",
    "    Function to test the model on new data after training it\n",
    "    on the full training data with the optimal number of epochs.\n",
    "    \n",
    "    Parameters:\n",
    "        model : trained model\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_test : test features\n",
    "        y_test : test target\n",
    "        epochs : optimal number of epochs\n",
    "    Output:\n",
    "        test accuracy and test loss\n",
    "    '''\n",
    "    model.fit(X_train\n",
    "              , y_train\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=BATCH_SIZE\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "[1 1 1 ... 1 1 1]\n",
      "NS: Intuition (N) – Sensing (S)\n",
      "[1 1 1 ... 1 0 1]\n",
      "FT: Feeling (F) - Thinking (T)\n",
      "[0 0 0 ... 1 1 0]\n",
      "JP: Judging (J) – Perceiving (P)\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "type_indicators = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) – Sensing (S)\", \n",
    "                   \"FT: Feeling (F) - Thinking (T)\", \"JP: Judging (J) – Perceiving (P)\"  ]\n",
    "\n",
    "for l in range(len(type_indicators)):\n",
    "    print(type_indicators[l])\n",
    "    print(y_test[:,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "    \n",
    "    print(X_train.shape, y_train_class.shape)\n",
    "    seed = 7    \n",
    "    model = XGBClassifier(learning_rate=0.01,\n",
    "                             n_estimators=100,\n",
    "                             max_depth=6,\n",
    "                             min_child_weight=6,\n",
    "                             colsample_bytree=0.7,\n",
    "                             objective='reg:logistic',\n",
    "                             nthread=8,\n",
    "                             scale_pos_weight=1,\n",
    "                             seed=7)\n",
    "\n",
    "    model.fit(X_train, y_train_class)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    prediction_proba = [value for value in y_pred]\n",
    "#     # evaluate predictions\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test_class, predictions)\n",
    "    f1_score_measure = sklearn.metrics.f1_score(y_test_class, predictions)\n",
    "    precision_measure = sklearn.metrics.precision_score(y_test_class, predictions)\n",
    "    recall_measure = sklearn.metrics.recall_score(y_test_class, predictions)\n",
    "    auc_roc = sklearn.metrics.roc_auc_score(y_test_class, predictions)\n",
    "#     mae = sklearn.metrics.mean_absolute_error(y_test_class, prediction_proba)\n",
    "    print(\" Accuracy: {:.3f} Precision: {:.3f} Recall {:.3f} F1-score {:.3f} ROC-AUC {:.3f}\".format(accuracy, \n",
    "                                                                                                    precision_measure, \n",
    "                                                                                                    recall_measure,\n",
    "                                                                                                   auc_roc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, AdaBoostRegressor, AdaBoostClassifier\n",
    "def rmse(y, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred - y)**2))\n",
    "rmse_scorer = sklearn.metrics.make_scorer(rmse, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "IE: Introversion (I) / Extroversion (E) ...\n",
      "(6907, 768) (6907,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE test: 0.4788521306805733 RMSE cv5: {'fit_time': array([2.52526259, 2.5362339 , 2.58612847, 2.56715107, 2.50232363]), 'score_time': array([0.194628  , 0.18550563, 0.18859291, 0.18550563, 0.18550563]), 'test_acc': array([0.77141204, 0.76909722, 0.76882966, 0.76825029, 0.77056779]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.73591385, 0.63501742, 0.61635008, 0.6080536 , 0.67760599]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.50764326, 0.50263073, 0.50490215, 0.50628519, 0.50691144]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.87036429, 0.86922321, 0.86879316, 0.86824769, 0.86982249]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.50764326, 0.50263073, 0.50490215, 0.50628519, 0.50691144]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([2.89527583, 2.91923833, 2.95810771, 2.92124009, 2.94414306,\n",
      "       2.9192121 , 2.96907949, 2.89029241, 2.9714458 , 2.93331194]), 'score_time': array([0.10671544, 0.10871005, 0.11469746, 0.10970354, 0.108711  ,\n",
      "       0.10870934, 0.10973334, 0.10671592, 0.1104188 , 0.10871077]), 'test_acc': array([0.7699422 , 0.77225434, 0.76940904, 0.76825029, 0.77056779,\n",
      "       0.77288528, 0.76709154, 0.76709154, 0.77172654, 0.76825029]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.68546512, 0.78604651, 0.38470452, 0.38457077, 0.71879845,\n",
      "       0.88604651, 0.57288012, 0.57288012, 0.71956437, 0.59979973]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.50599624, 0.50924812, 0.5       , 0.49924699, 0.50427211,\n",
      "       0.50753769, 0.50377263, 0.50377263, 0.50854423, 0.50452564]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.8695082 , 0.87081967, 0.86967911, 0.8689384 , 0.87007874,\n",
      "       0.87139108, 0.8676761 , 0.8676761 , 0.87047995, 0.86842105]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.50599624, 0.50924812, 0.5       , 0.49924699, 0.50427211,\n",
      "       0.50753769, 0.50377263, 0.50377263, 0.50854423, 0.50452564]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "NS: Intuition (N) – Sensing (S) ...\n",
      "(6907, 768) (6907,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE test: 0.37818326577603667 RMSE cv5: {'fit_time': array([2.69784021, 2.65193081, 2.67683196, 2.72273397, 2.67887926]), 'score_time': array([0.180516  , 0.17752552, 0.18151641, 0.18450737, 0.17952895]), 'test_acc': array([0.86111111, 0.86284722, 0.86210892, 0.86326767, 0.86210892]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.43105446, 0.9313839 , 0.43130435, 0.9315942 , 0.43130435]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.49932886, 0.50210084, 0.4996642 , 0.5021097 , 0.4996642 ]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.92537313, 0.92632888, 0.92594897, 0.92657125, 0.92594897]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.49932886, 0.50210084, 0.4996642 , 0.5021097 , 0.4996642 ]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([3.29728341, 3.1528511 , 3.18051481, 3.28326988, 3.17948985,\n",
      "       3.24984598, 3.27916217, 3.24469447, 3.23298216, 3.31627941]), 'score_time': array([0.1093905 , 0.11070609, 0.1127274 , 0.10970545, 0.10873747,\n",
      "       0.11575794, 0.10870934, 0.10871053, 0.10970783, 0.11266994]), 'test_acc': array([0.86111111, 0.86226852, 0.86226852, 0.86342593, 0.86226852,\n",
      "       0.86226852, 0.86342593, 0.86194896, 0.86078886, 0.86310905]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.43105446, 0.43113426, 0.43113426, 0.93163384, 0.68155452,\n",
      "       0.43113426, 0.93163384, 0.43147503, 0.43139535, 0.43155452]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.49932886, 0.5       , 0.5       , 0.50420168, 0.50353054,\n",
      "       0.5       , 0.50420168, 0.49932796, 0.49865591, 0.5       ]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.92537313, 0.92604102, 0.92604102, 0.92661692, 0.92594897,\n",
      "       0.92604102, 0.92661692, 0.9258567 , 0.92518703, 0.92652553]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.49932886, 0.5       , 0.5       , 0.50420168, 0.50353054,\n",
      "       0.5       , 0.50420168, 0.49932796, 0.49865591, 0.5       ]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "FT: Feeling (F) - Thinking (T) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5155373964903818 RMSE cv5: {'fit_time': array([2.59115028, 2.60825491, 2.6429491 , 2.63895917, 2.52967095]), 'score_time': array([0.1934855 , 0.20146275, 0.19049191, 0.20146322, 0.19347572]), 'test_acc': array([0.72727273, 0.73943254, 0.73190504, 0.74696005, 0.70857474]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.72929913, 0.74032568, 0.73529721, 0.74736356, 0.70742197]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.71964498, 0.73309566, 0.72363339, 0.74130273, 0.70318144]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.67849829, 0.69798658, 0.68090972, 0.70924817, 0.66754792]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.71964498, 0.73309566, 0.72363339, 0.74130273, 0.70318144]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([2.92961907, 2.95729947, 3.05436873, 2.95144486, 2.99748611,\n",
      "       3.06031489, 3.09277892, 2.90235758, 2.94223881, 2.90335178]), 'score_time': array([0.10870957, 0.11170244, 0.1117003 , 0.11083364, 0.11077285,\n",
      "       0.11469436, 0.10970783, 0.10769987, 0.10870934, 0.10771775]), 'test_acc': array([0.73032407, 0.74305556, 0.7349537 , 0.75578704, 0.73232908,\n",
      "       0.74044032, 0.73232908, 0.74391657, 0.73580533, 0.68829664]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.73021113, 0.7485618 , 0.73373045, 0.75755996, 0.73622142,\n",
      "       0.74358183, 0.731966  , 0.74352342, 0.73837761, 0.68607493]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.7244561 , 0.73407148, 0.73067211, 0.74932012, 0.72388229,\n",
      "       0.73272068, 0.72695369, 0.73900407, 0.72824606, 0.68569258]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.689747  , 0.6908078 , 0.70143416, 0.71601615, 0.68049793,\n",
      "       0.69315068, 0.69403974, 0.7088274 , 0.68852459, 0.65819568]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.7244561 , 0.73407148, 0.73067211, 0.74932012, 0.72388229,\n",
      "       0.73272068, 0.72695369, 0.73900407, 0.72824606, 0.68569258]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "JP: Judging (J) – Perceiving (P) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5884430301808192 RMSE cv5: {'fit_time': array([2.82669258, 2.87333441, 2.83553433, 2.79854536, 2.89524555]), 'score_time': array([0.21742034, 0.19946814, 0.20246077, 0.21740651, 0.20744658]), 'test_acc': array([0.625     , 0.63252315, 0.64484357, 0.63904983, 0.62514484]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.60338699, 0.61384178, 0.65424362, 0.62647065, 0.60088456]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.55278282, 0.56556261, 0.56893197, 0.57146577, 0.55667568]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.30322581, 0.34468524, 0.31354983, 0.35171696, 0.32533889]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.55278282, 0.56556261, 0.56893197, 0.57146577, 0.55667568]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([3.33809423, 3.31016898, 3.36402512, 3.31832361, 3.20345879,\n",
      "       3.22772884, 3.22038078, 3.1645577 , 3.24035525, 3.21841407]), 'score_time': array([0.12267303, 0.12067819, 0.11968112, 0.11668563, 0.11568761,\n",
      "       0.11665869, 0.11868358, 0.11569166, 0.11668873, 0.11968136]), 'test_acc': array([0.63541667, 0.63888889, 0.63657407, 0.6400463 , 0.64814815,\n",
      "       0.64351852, 0.63078704, 0.63921114, 0.61948956, 0.62064965]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.62696942, 0.6239997 , 0.62234998, 0.62681406, 0.64826766,\n",
      "       0.63995354, 0.61708372, 0.63011964, 0.5917137 , 0.59812951]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.56215971, 0.57360355, 0.56866304, 0.57405727, 0.57824158,\n",
      "       0.57289776, 0.55732002, 0.56881083, 0.54692364, 0.5428175 ]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.31372549, 0.36326531, 0.34583333, 0.3613963 , 0.35319149,\n",
      "       0.34188034, 0.30501089, 0.33688699, 0.29310345, 0.26185102]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.56215971, 0.57360355, 0.56866304, 0.57405727, 0.57824158,\n",
      "       0.57289776, 0.55732002, 0.56881083, 0.54692364, 0.5428175 ]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "    \n",
    "    print(X_train.shape, y_train_class.shape)\n",
    "    seed = 7    \n",
    "    \n",
    "    model = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "    model.fit(X_train, y_train_class)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "#     # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test_class, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test_class, predictions)\n",
    "    rmse_val = rmse(y_test_class, predictions)\n",
    "    scoring = {'acc': 'accuracy',\n",
    "               'prec': 'precision_macro',\n",
    "               'rec': 'recall_macro',\n",
    "               'f1': sklearn.metrics.make_scorer(sklearn.metrics.f1_score),\n",
    "               'roc_auc': sklearn.metrics.make_scorer(sklearn.metrics.roc_auc_score)}\n",
    "    rmse_cv_5 = cross_validate(model, np.array(list_posts_vec), np.array(list_personality_vec)[:,l], cv=5, scoring=scoring)\n",
    "    rmse_cv_10 = cross_validate(model,np.array(list_posts_vec), np.array(list_personality_vec)[:,l], cv=10, scoring=scoring)\n",
    "    print(\" RMSE test: {} RMSE cv5: {} RMSE cv10: {}\".format(rmse_val, rmse_cv_5, rmse_cv_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "IE: Introversion (I) / Extroversion (E) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5884430301808192 RMSE cv5: {'fit_time': array([1.38729429, 1.41123462, 1.39530492, 1.44916201, 1.38034463]), 'score_time': array([0.09973335, 0.10175776, 0.10073161, 0.10172868, 0.09873652]), 'test_acc': array([0.76851852, 0.76851852, 0.76535342, 0.76651217, 0.76651217]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.62274029, 0.62534744, 0.57968408, 0.58981318, 0.58144196]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.50751597, 0.50926979, 0.50792176, 0.507795  , 0.50603545]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.86833443, 0.86816084, 0.86602713, 0.86686488, 0.86704058]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.50751597, 0.50926979, 0.50792176, 0.507795  , 0.50603545]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([1.63164616, 1.6047461 , 1.60674191, 1.59577036, 1.61272526,\n",
      "       1.62865257, 1.6177125 , 1.61668634, 1.5987339 , 1.61972499]), 'score_time': array([0.05884528, 0.05784822, 0.05784464, 0.05684757, 0.05884242,\n",
      "       0.05881572, 0.05785346, 0.05884314, 0.05884314, 0.05784369]), 'test_acc': array([0.7699422 , 0.7699422 , 0.76825029, 0.7636153 , 0.76477404,\n",
      "       0.77867903, 0.77172654, 0.7589803 , 0.76477404, 0.76825029]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.66387591, 0.65914413, 0.6080536 , 0.38403263, 0.58083498,\n",
      "       0.78213865, 0.69904971, 0.51665004, 0.50979532, 0.61342296]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.50949248, 0.5112406 , 0.50628519, 0.49623494, 0.50930481,\n",
      "       0.52537915, 0.51030378, 0.50202065, 0.50050705, 0.50804474]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.86916502, 0.86899276, 0.86824769, 0.86596583, 0.86547382,\n",
      "       0.87376074, 0.87030941, 0.86206897, 0.86635945, 0.86807388]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.50949248, 0.5112406 , 0.50628519, 0.49623494, 0.50930481,\n",
      "       0.52537915, 0.51030378, 0.50202065, 0.50050705, 0.50804474]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "NS: Intuition (N) – Sensing (S) ...\n",
      "(6907, 768) (6907,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE test: 0.5884430301808192 RMSE cv5: {'fit_time': array([1.48404479, 1.47309756, 1.48706031, 1.48406744, 1.46212959]), 'score_time': array([0.10471725, 0.10073113, 0.09474969, 0.10073423, 0.09886718]), 'test_acc': array([0.86111111, 0.86284722, 0.86384705, 0.86326767, 0.86095017]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.5562645 , 0.73180499, 0.93184455, 0.76513832, 0.43122461]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.50109413, 0.50563138, 0.50421941, 0.50388361, 0.49899261]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.9253267 , 0.92623716, 0.92685963, 0.92652553, 0.9252802 ]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.50109413, 0.50563138, 0.50421941, 0.50388361, 0.49899261]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([1.71043587, 1.72442722, 1.70148993, 1.68852282, 1.75634456,\n",
      "       1.72149014, 1.71143341, 1.70352864, 1.72240806, 1.70444608]), 'score_time': array([0.05981278, 0.05784488, 0.05784345, 0.056849  , 0.06180406,\n",
      "       0.05981255, 0.05884314, 0.05784535, 0.05783963, 0.05684614]), 'test_acc': array([0.86226852, 0.8587963 , 0.86574074, 0.86226852, 0.86226852,\n",
      "       0.86226852, 0.86226852, 0.86426914, 0.86194896, 0.86078886]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.43113426, 0.43089431, 0.93263647, 0.68155452, 0.43113426,\n",
      "       0.43113426, 0.68155452, 0.93205575, 0.43147503, 0.43139535]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.5       , 0.49798658, 0.51260504, 0.50353054, 0.5       ,\n",
      "       0.5       , 0.50353054, 0.50423729, 0.49932796, 0.49865591]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.92604102, 0.92403487, 0.92777086, 0.92594897, 0.92604102,\n",
      "       0.92604102, 0.92594897, 0.9271028 , 0.9258567 , 0.92518703]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.5       , 0.49798658, 0.51260504, 0.50353054, 0.5       ,\n",
      "       0.5       , 0.50353054, 0.50423729, 0.49932796, 0.49865591]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "FT: Feeling (F) - Thinking (T) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5884430301808192 RMSE cv5: {'fit_time': array([1.34840083, 1.39926386, 1.34640384, 1.35637689, 1.36034322]), 'score_time': array([0.09873652, 0.09774137, 0.09674001, 0.0977416 , 0.09973431]), 'test_acc': array([0.71627099, 0.73190504, 0.72785177, 0.72669369, 0.71320973]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.71741032, 0.73182387, 0.73292486, 0.72744269, 0.71225552]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.70880867, 0.72614379, 0.71853832, 0.7199792 , 0.70775204]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.66666667, 0.69194943, 0.67132867, 0.6819407 , 0.67240238]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.70880867, 0.72614379, 0.71853832, 0.7199792 , 0.70775204]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([1.55983758, 1.55983734, 1.55385327, 1.56781602, 1.61172724,\n",
      "       1.58078146, 1.57579255, 1.58976483, 1.58576989, 1.6107285 ]), 'score_time': array([0.05784559, 0.05784607, 0.05784583, 0.05784607, 0.05984116,\n",
      "       0.05983877, 0.05984092, 0.05883265, 0.05884194, 0.05983925]), 'test_acc': array([0.72453704, 0.73032407, 0.7349537 , 0.74421296, 0.71378911,\n",
      "       0.71958285, 0.7161066 , 0.74507532, 0.72421784, 0.68829664]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.72338534, 0.73726764, 0.73362072, 0.74732669, 0.71652631,\n",
      "       0.72591145, 0.71999977, 0.74633969, 0.73007669, 0.68606936]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.71969697, 0.7201826 , 0.73086636, 0.73649961, 0.70521597,\n",
      "       0.70941752, 0.70697337, 0.73873099, 0.71446802, 0.68434884]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.68766404, 0.67043847, 0.70221066, 0.69767442, 0.65836791,\n",
      "       0.6572238 , 0.65829847, 0.70430108, 0.66478873, 0.65200517]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.71969697, 0.7201826 , 0.73086636, 0.73649961, 0.70521597,\n",
      "       0.70941752, 0.70697337, 0.73873099, 0.71446802, 0.68434884]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "JP: Judging (J) – Perceiving (P) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5884430301808192 RMSE cv5: {'fit_time': array([1.51392984, 1.47403646, 1.52592826, 1.48603487, 1.46608806]), 'score_time': array([0.10275507, 0.10272574, 0.10272598, 0.10272598, 0.10372305]), 'test_acc': array([0.6255787 , 0.6255787 , 0.63615295, 0.62977984, 0.62804171]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.60150834, 0.60225226, 0.62260848, 0.61053147, 0.60466574]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.55779895, 0.55653862, 0.56704742, 0.5602581 , 0.56235743]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.32953368, 0.32251309, 0.33894737, 0.32665964, 0.34489796]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.55779895, 0.55653862, 0.56704742, 0.5602581 , 0.56235743]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([1.69849539, 1.7263906 , 1.70345402, 1.71043301, 1.70142913,\n",
      "       1.77725363, 1.72339606, 1.69448495, 1.7034564 , 1.70542026]), 'score_time': array([0.06083703, 0.06183505, 0.06180477, 0.06183457, 0.06183529,\n",
      "       0.06083775, 0.06083989, 0.05980659, 0.06083298, 0.06283259]), 'test_acc': array([0.62847222, 0.62731481, 0.62268519, 0.625     , 0.63657407,\n",
      "       0.63310185, 0.62037037, 0.64269142, 0.63109049, 0.63805104]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.60744084, 0.60388446, 0.59529412, 0.5982906 , 0.62406855,\n",
      "       0.62131295, 0.59235617, 0.63005356, 0.61156054, 0.62557441]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.55994152, 0.5610002 , 0.55716878, 0.56261343, 0.56715064,\n",
      "       0.560244  , 0.55122   , 0.5777689 , 0.56310614, 0.56937088]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.32985386, 0.34016393, 0.33739837, 0.35714286, 0.33755274,\n",
      "       0.31236443, 0.31380753, 0.37142857, 0.3375    , 0.34453782]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.55994152, 0.5610002 , 0.55716878, 0.56261343, 0.56715064,\n",
      "       0.560244  , 0.55122   , 0.5777689 , 0.56310614, 0.56937088]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "    \n",
    "    print(X_train.shape, y_train_class.shape)\n",
    "    seed = 7    \n",
    "    \n",
    "    model = AdaBoostClassifier(ExtraTreesClassifier(n_estimators=50), \n",
    "                              n_estimators=50, \n",
    "                              learning_rate =0.1, \n",
    "                              random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train_class)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "#     # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test_class, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test_class, predictions)\n",
    "    scoring = {'acc': 'accuracy',\n",
    "               'prec': 'precision_macro',\n",
    "               'rec': 'recall_macro',\n",
    "               'f1': sklearn.metrics.make_scorer(sklearn.metrics.f1_score),\n",
    "               'roc_auc': sklearn.metrics.make_scorer(sklearn.metrics.roc_auc_score)}\n",
    "    rmse_cv_5 = cross_validate(model, np.array(list_posts_vec), np.array(list_personality_vec)[:,l], cv=5, scoring=scoring)\n",
    "    rmse_cv_10 = cross_validate(model,np.array(list_posts_vec), np.array(list_personality_vec)[:,l], cv=10, scoring=scoring)\n",
    "    print(\" RMSE test: {} RMSE cv5: {} RMSE cv10: {}\".format(rmse_val, rmse_cv_5, rmse_cv_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Posts in tf-idf representation\n",
    "\n",
    "# Let's train type indicator individually\n",
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    # Let's train type indicator individually\n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "\n",
    "    # split data into train and test sets\n",
    "    model = svm.LinearSVR(C=10)\n",
    "\n",
    "    clf = model.fit(X_train, y_train_class)\n",
    "    \n",
    "#     pca = PCA(n_components=2).fit(X_train_seq_trunc)\n",
    "    \n",
    "#     pca_2d = pca.transform(X_train_seq_trunc)\n",
    "    \n",
    "#     svmClassifier_2d =   svm.LinearSVC(C=10,\n",
    "#                           class_weight='balanced').fit(   pca_2d, y_train_class)\n",
    "    \n",
    "#     for i in range(0, pca_2d.shape[0]):\n",
    "#         if y_train_res[i] == 0:\n",
    "#             c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='r', s=50,marker='+')\n",
    "#         elif y_train_res[i] == 1:\n",
    "#             c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g',    s=50,marker='o')\n",
    "    \n",
    "#     pl.legend([c1, c2], [type_indicators[l][0], type_indicators[l][1]])\n",
    "#     x_min, x_max = pca_2d[:, 0].min() - 1,   pca_2d[:,0].max() + 1\n",
    "#     y_min, y_max = pca_2d[:, 1].min() - 1,   pca_2d[:, 1].max() + 1\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, .01),   np.arange(y_min, y_max, .01))\n",
    "#     Z = svmClassifier_2d.predict(np.c_[xx.ravel(),  yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     pl.contour(xx, yy, Z)\n",
    "#     pl.title('Support Vector Machine Decision Surface')\n",
    "#     pl.axis('off')\n",
    "#     pl.show()\n",
    "    \n",
    "    # make predictions  for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test, predictions)\n",
    "    rmse_val = rmse(y_test_class, predictions)\n",
    "    mae = sklearn.metrics.mean_absolute_error(y_test_class, predictions)\n",
    "    print(\" RMSE: {:.3f} MAE: {:.3f}\".format(rmse_val, mae))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
