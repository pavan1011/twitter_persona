{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT \n",
    "https://colab.research.google.com/drive/1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU#scrollTo=E_t4cM6KLc98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# * File:    Twitter_Persona_GloVe.py\n",
    "# *\n",
    "# * Author1:  Pavan Kumar K N (pavankumar.karkekopp@ucalgary.ca)\n",
    "# * Date:     11th Aug 2019\n",
    "# * Summary of File:\n",
    "# * Explore mbti_1.csv file acquired from https://www.kaggle.com/datasnaek/mbti-type\n",
    "# * Apply state-of-the-art reported publicly\n",
    "# * Build classifier model that is better using machine learning techniques\n",
    "\n",
    "#Just making sure the right environment is running this script\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# # Load pre-trained model tokenizer (vocabulary)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_types(row):\n",
    "    t=row['type']\n",
    "\n",
    "    I = 0\n",
    "    N = 0\n",
    "    T = 0\n",
    "    J = 0\n",
    "    \n",
    "    if t[0] == 'I': I = 1\n",
    "    elif t[0] == 'E': I = 0\n",
    "    else: print('Could not identify label for I-E')\n",
    "        \n",
    "    if t[1] == 'N': N = 1\n",
    "    elif t[1] == 'S': N = 0\n",
    "    else: print('Could not identify label for N-S')\n",
    "        \n",
    "    if t[2] == 'T': T = 1\n",
    "    elif t[2] == 'F': T = 0\n",
    "    else: print('Could not identify label for T-F')\n",
    "        \n",
    "    if t[3] == 'J': J = 1\n",
    "    elif t[3] == 'P': J = 0\n",
    "    else: print('Could not identify label for J-P')\n",
    "    return pd.Series( {'IE':I, 'NS':N , 'TF': T, 'JP': J }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to binarize the types into simple lists instead of pandas.series\n",
    "personality_binary = {'I':1, 'E':0, 'N':1,'S':0, 'T':1, 'F':0, 'J':1, 'P': 0}\n",
    "binary_personality = [{1:'I', 0:'E'}, \n",
    "                      {1:'N', 0:'S'},\n",
    "                      {1:'T', 0:'F'},\n",
    "                      {1:'J', 0:'P'}]\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    return [personality_binary[l] for l in personality]\n",
    "\n",
    "\n",
    "def translate_binary(personality):\n",
    "    # transform binary vector to mbti personality\n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += binary_personality[i][l]\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseMBTI(mbti_file_path): \n",
    "    \n",
    "    \n",
    "    #List of strings to remove from the corpus\n",
    "    unique_type_list = ['INFJ', \n",
    "                        'ENTP', \n",
    "                        'INTP', \n",
    "                        'INTJ', \n",
    "                        'ENTJ', \n",
    "                        'ENFJ', \n",
    "                        'INFP', \n",
    "                        'ENFP',\n",
    "                        'ISFP', \n",
    "                        'ISTP', \n",
    "                        'ISFJ', \n",
    "                        'ISTJ', \n",
    "                        'ESTP', \n",
    "                        'ESFP', \n",
    "                        'ESTJ', \n",
    "                        'ESFJ']\n",
    "    list_personality = []\n",
    "    list_posts = []\n",
    "    \n",
    "\n",
    "    \n",
    "    # Initialize for Lemmatization\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "    #List of unique types of personality\n",
    "    unique_type_list = [x.lower() for x in unique_type_list]\n",
    "\n",
    "    #Read file\n",
    "    mbti_data = pd.read_csv(mbti_file_path)\n",
    "\n",
    "\n",
    "    raw_posts = mbti_data.posts.values\n",
    "    filtered_posts = [p.split(\"|||\") for p in raw_posts]\n",
    "    mbti_data_encoded = mbti_data.join(mbti_data.apply(lambda row: encode_types(row), axis=1))\n",
    "    \n",
    "    len_data = len(mbti_data_encoded)\n",
    "    i=0\n",
    "    \n",
    "    \n",
    "    for row in mbti_data_encoded.iterrows():\n",
    "        i+=1\n",
    "        tweets = []\n",
    "\n",
    "        if (i % 500 == 0 or i == 1 or i == len_data):\n",
    "            print(\"%s of %s rows\" % (i, len_data))\n",
    "\n",
    "        ##### Remove and clean comments\n",
    "        posts = row[1].posts\n",
    "        \n",
    "        for tweet_string in posts.split(\"|||\"):\n",
    "            #Removing mentions\n",
    "            tweet_string = tweet_string.replace('@username', '')\n",
    "            #Removing unecessary spaces\n",
    "\n",
    "            #Removing URL\n",
    "            tweet_string = re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", tweet_string)\n",
    "            tweet_string = tweet_string.strip()\n",
    "            tweets.append(tweet_string)\n",
    "\n",
    "        j=0\n",
    "        for pos in tweets:\n",
    "            if pos is not None:\n",
    "                pos = re.sub(\"[^a-zA-Z]\", \" \", pos)\n",
    "                pos = re.sub(\" +\", \" \", pos).lower()\n",
    "                pos = \" \".join([lemmatiser.lemmatize(w) for w in pos.split(' ')])\n",
    "\n",
    "                if pos!= \" \":\n",
    "                    tweets[j] = pos\n",
    "                else:\n",
    "                    tweets[j] = None\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        tweets = list(filter(None, tweets))\n",
    "\n",
    "        #'Add [SEP] tokens for BERT tokenizer'\n",
    "        processed_tweets = '[SEP]'.join(tweets)\n",
    "        list_posts.append(processed_tweets)\n",
    "        list_personality.append(translate_personality(row[1].type))\n",
    "    return np.array(list_posts), np.array(list_personality)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
    "#         temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
    "#         temp = re.sub(' +', ' ', temp).strip().lower()\n",
    "#         if remove_stop_words:\n",
    "#             temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in stopwords.words(\"english\")])\n",
    "#         else:\n",
    "#             temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n",
    "            \n",
    "#         if remove_mbti_profiles:\n",
    "#             for t in unique_type_list:\n",
    "#                 temp = temp.replace(t,\"\")\n",
    "\n",
    "#         type_labelized = translate_personality(row[1].type)\n",
    "#         list_personality.append(type_labelized)\n",
    "#         list_posts.append(temp)\n",
    "\n",
    "#     list_posts = np.array(list_posts)\n",
    "#     list_personality = np.array(list_personality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 8675 rows\n",
      "500 of 8675 rows\n",
      "1000 of 8675 rows\n",
      "1500 of 8675 rows\n",
      "2000 of 8675 rows\n",
      "2500 of 8675 rows\n",
      "3000 of 8675 rows\n",
      "3500 of 8675 rows\n",
      "4000 of 8675 rows\n",
      "4500 of 8675 rows\n",
      "5000 of 8675 rows\n",
      "5500 of 8675 rows\n",
      "6000 of 8675 rows\n",
      "6500 of 8675 rows\n",
      "7000 of 8675 rows\n",
      "7500 of 8675 rows\n",
      "8000 of 8675 rows\n",
      "8500 of 8675 rows\n",
      "8675 of 8675 rows\n"
     ]
    }
   ],
   "source": [
    "list_posts, list_personality = parseMBTI(\"data/mbti_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(list_posts, open(\"output/list_posts_mbti_bert.p\", \"wb\"))\n",
    "pickle.dump(list_personality, open(\"output/list_personality_mbti_bert.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posts = pickle.load(open(\"output/list_posts_mbti_bert.p\", \"rb\"))\n",
    "list_personality = pickle.load(open(\"output/list_personality_mbti_bert.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posts[0], list_personality[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "bert_model.eval()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 8675 rows\n",
      "100 of 8675 rows\n",
      "200 of 8675 rows\n",
      "300 of 8675 rows\n",
      "400 of 8675 rows\n",
      "500 of 8675 rows\n",
      "600 of 8675 rows\n",
      "700 of 8675 rows\n",
      "800 of 8675 rows\n",
      "900 of 8675 rows\n",
      "1000 of 8675 rows\n",
      "1100 of 8675 rows\n",
      "1200 of 8675 rows\n",
      "1300 of 8675 rows\n",
      "1400 of 8675 rows\n",
      "1500 of 8675 rows\n",
      "1600 of 8675 rows\n",
      "1700 of 8675 rows\n",
      "1800 of 8675 rows\n",
      "1900 of 8675 rows\n",
      "2000 of 8675 rows\n",
      "2100 of 8675 rows\n",
      "2200 of 8675 rows\n",
      "2300 of 8675 rows\n",
      "2400 of 8675 rows\n",
      "2500 of 8675 rows\n",
      "2600 of 8675 rows\n",
      "2700 of 8675 rows\n",
      "2800 of 8675 rows\n",
      "2900 of 8675 rows\n",
      "3000 of 8675 rows\n",
      "3100 of 8675 rows\n",
      "3200 of 8675 rows\n",
      "3300 of 8675 rows\n",
      "3400 of 8675 rows\n",
      "3500 of 8675 rows\n",
      "3600 of 8675 rows\n",
      "3700 of 8675 rows\n",
      "3800 of 8675 rows\n",
      "3900 of 8675 rows\n",
      "4000 of 8675 rows\n",
      "4100 of 8675 rows\n",
      "4200 of 8675 rows\n",
      "4300 of 8675 rows\n",
      "4400 of 8675 rows\n",
      "4500 of 8675 rows\n",
      "4600 of 8675 rows\n",
      "4700 of 8675 rows\n",
      "4800 of 8675 rows\n",
      "4900 of 8675 rows\n",
      "5000 of 8675 rows\n",
      "5100 of 8675 rows\n",
      "5200 of 8675 rows\n",
      "5300 of 8675 rows\n",
      "5400 of 8675 rows\n",
      "5500 of 8675 rows\n",
      "5600 of 8675 rows\n",
      "5700 of 8675 rows\n",
      "5800 of 8675 rows\n",
      "5900 of 8675 rows\n",
      "6000 of 8675 rows\n",
      "6100 of 8675 rows\n",
      "6200 of 8675 rows\n",
      "6300 of 8675 rows\n",
      "6400 of 8675 rows\n",
      "6500 of 8675 rows\n",
      "6600 of 8675 rows\n",
      "6700 of 8675 rows\n",
      "6800 of 8675 rows\n",
      "6900 of 8675 rows\n",
      "7000 of 8675 rows\n",
      "7100 of 8675 rows\n",
      "7200 of 8675 rows\n",
      "7300 of 8675 rows\n",
      "7400 of 8675 rows\n",
      "7500 of 8675 rows\n",
      "7600 of 8675 rows\n",
      "7700 of 8675 rows\n",
      "7800 of 8675 rows\n",
      "7900 of 8675 rows\n",
      "8000 of 8675 rows\n",
      "8100 of 8675 rows\n",
      "8200 of 8675 rows\n",
      "8300 of 8675 rows\n",
      "8400 of 8675 rows\n",
      "8500 of 8675 rows\n",
      "8600 of 8675 rows\n",
      "8675 of 8675 rows\n"
     ]
    }
   ],
   "source": [
    "#Specify max_token_length according to above\n",
    "max_token_length = 256\n",
    "list_posts_vec = []\n",
    "list_personality_vec = []\n",
    "list_posts_len = len(list_posts)\n",
    "\n",
    "count_progress = 0\n",
    "for posts, personality in zip(list_posts, list_personality):\n",
    "    \n",
    "    count_progress += 1\n",
    "    sentence_list = posts.split('[SEP]')\n",
    "    running_token_len = 0\n",
    "    sentence_count = 0\n",
    "    tweet_stream_vec_list = []\n",
    "    text_batch_list = []\n",
    "    text = \"\"\n",
    "    \n",
    "    if (count_progress % 100 == 0 or count_progress == 1 or count_progress == list_posts_len):\n",
    "            print(\"{} of {} rows\".format(count_progress, list_posts_len))\n",
    "            \n",
    "    #Split the sequence of tweets into separate batches of max_token_length\n",
    "    for sentence in sentence_list:\n",
    "        \n",
    "        sentence_len = len(sentence.strip().split(' '))\n",
    "#         print(\" \\Sentence Length: {}\\n  \\nRunning Token Length: {}\".format(sentence_len, running_token_len))\n",
    "        #Case 1: Sentence is smaller than max token_length\n",
    "        if(sentence_len <= max_token_length):\n",
    "           \n",
    "           #Concatenate into single post\n",
    "            if(running_token_len + sentence_len < max_token_length):\n",
    "                running_token_len += sentence_len\n",
    "                text += sentence\n",
    "            \n",
    "            else:\n",
    "                if text!= \"\":\n",
    "                    text_batch_list.append(text)\n",
    "                sentence_count += 1\n",
    "                running_token_len = sentence_len\n",
    "                text = sentence\n",
    "           \n",
    "        \n",
    "        else:\n",
    "            if text!= \"\":\n",
    "                text_batch_list.append(text)\n",
    "            text_len = len(sentence.strip().split(' '))\n",
    "            \n",
    "            while(text_len > max_token_length):\n",
    "                text_batch_list.append( \" \".join(sentence.strip().split(' ')[:max_token_length]))\n",
    "                sentence = \" \".join(sentence.strip().split(' ')[max_token_length:])\n",
    "                text_len = len(sentence.strip().split(' '))\n",
    "            \n",
    "            running_token_len = sentence_len\n",
    "            text = sentence\n",
    "        \n",
    "#     print(\"Total batches: {}\\n{}\".format(len(text_batch_list), [len(text.strip().split(' ')) for text in text_batch_list]))\n",
    "\n",
    "    #Process the batches\n",
    "    for text in text_batch_list:\n",
    "        marked_text = \"[CLS]\" + text + \"[SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#         print(marked_text)\n",
    "#         print((tokenized_text))\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        \n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        \n",
    "#         print(tokens_tensor.shape, segments_tensors.shape)\n",
    "        # Predict hidden states features for each layer\n",
    "        with torch.no_grad():\n",
    "            encoded_layers, _ = bert_model(tokens_tensor, segments_tensors)\n",
    "            \n",
    "        token_embeddings = [] \n",
    "\n",
    "        batch_i = 0 #Since we have only one sentence\n",
    "        # For each token in the sentence...\n",
    "        for token_i in range(len(tokenized_text)):\n",
    "\n",
    "            # Holds 12 layers of hidden states for each token \n",
    "            hidden_layers = [] \n",
    "\n",
    "            # For each of the 12 layers...\n",
    "            for layer_i in range(len(encoded_layers)):\n",
    "\n",
    "                # Lookup the vector for `token_i` in `layer_i`\n",
    "                vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "                hidden_layers.append(vec)\n",
    "\n",
    "        token_embeddings.append(hidden_layers)\n",
    "\n",
    "        # Stores the token vectors, with shape [22 x 768]\n",
    "        token_vecs_sum = []\n",
    "\n",
    "        # For each token in the sentence...\n",
    "        for token in token_embeddings:\n",
    "            # Sum the vectors from the last four layers.\n",
    "            sum_vec = torch.sum(torch.stack(token)[-4:], 0)\n",
    "\n",
    "            # Use `sum_vec` to represent `token`.\n",
    "            token_vecs_sum.append(sum_vec)\n",
    "        \n",
    "        sentence_embedding = torch.mean(encoded_layers[11], 1)\n",
    "        tweet_stream_vec_list.append(sentence_embedding)\n",
    "        \n",
    "    #Concatenate the stream vector into one vector to represent the whole stream\n",
    "    if(len(tweet_stream_vec_list) > 0):\n",
    "        tweet_stream_vec = torch.mean(torch.stack(tweet_stream_vec_list), dim=0)\n",
    "        list_posts_vec.append(tweet_stream_vec.numpy().ravel())\n",
    "        list_personality_vec.append(personality)\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8634, 768), (8634, 4))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list_posts_vec).shape, np.array(list_personality_vec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(list_posts, open(\"output/list_posts_vec_mbti_bert.p\", \"wb\"))\n",
    "pickle.dump(list_personality, open(\"output/list_personality_vec_mbti_bert.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posts = pickle.load(open(\"output/list_posts_mbti_bert.p\", \"rb\"))\n",
    "list_personality = pickle.load(open(\"output/list_personality_mbti_bert.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(list_posts_vec), np.array(list_personality_vec), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred - y)**2))\n",
    "\n",
    "def deep_model(model, X_train, y_train, X_valid, y_valid):\n",
    "    '''\n",
    "    Function to train a multi-class model. The number of epochs and \n",
    "    batch_size are set by the constants at the top of the\n",
    "    notebook. \n",
    "    \n",
    "    Parameters:\n",
    "        model : model with the chosen architecture\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_valid : validation features\n",
    "        Y_valid : validation target\n",
    "    Output:\n",
    "        model training history\n",
    "    '''\n",
    "    model.compile(optimizer='rmsprop'\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train\n",
    "                       , y_train\n",
    "                       , epochs=NB_START_EPOCHS\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       , verbose=1)\n",
    "    return history\n",
    "\n",
    "\n",
    "def eval_metric(history, metric_name):\n",
    "    '''\n",
    "    Function to evaluate a trained model on a chosen metric. \n",
    "    Training and validation metric are plotted in a\n",
    "    line chart for each epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        history : model training history\n",
    "        metric_name : loss or accuracy\n",
    "    Output:\n",
    "        line chart with epochs of x-axis and metric on\n",
    "        y-axis\n",
    "    '''\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name]\n",
    "\n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n",
    "    '''\n",
    "    Function to test the model on new data after training it\n",
    "    on the full training data with the optimal number of epochs.\n",
    "    \n",
    "    Parameters:\n",
    "        model : trained model\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_test : test features\n",
    "        y_test : test target\n",
    "        epochs : optimal number of epochs\n",
    "    Output:\n",
    "        test accuracy and test loss\n",
    "    '''\n",
    "    \n",
    "    model.fit(X_train\n",
    "              , y_train\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=BATCH_SIZE\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    type_indicators = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) – Sensing (S)\", \n",
    "                   \"FT: Feeling (F) - Thinking (T)\", \"JP: Judging (J) – Perceiving (P)\"  ]\n",
    "\n",
    "    for l in range(len(type_indicators)):\n",
    "        print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "        predictions = [round(value) for value in y_pred[:,l]]\n",
    "        prec = sklearn.metrics.precision_score(predictions,y_test[:,l])\n",
    "        rec = sklearn.metrics.recall_score(predictions,y_test[:,l])\n",
    "        f1 = sklearn.metrics.f1_score(predictions,y_test[:,l]),\n",
    "        roc_auc = sklearn.metrics.roc_auc_score(predictions,y_test[:,l])\n",
    "        print(\" Prec: {} Rec: {}  f1:{} Auc:{}\".format(prec, rec, f1, roc_auc))\n",
    "\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "[1 1 1 ... 1 1 1]\n",
      "NS: Intuition (N) – Sensing (S)\n",
      "[1 1 1 ... 1 0 1]\n",
      "FT: Feeling (F) - Thinking (T)\n",
      "[0 0 0 ... 1 1 0]\n",
      "JP: Judging (J) – Perceiving (P)\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "type_indicators = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) – Sensing (S)\", \n",
    "                   \"FT: Feeling (F) - Thinking (T)\", \"JP: Judging (J) – Perceiving (P)\"  ]\n",
    "\n",
    "for l in range(len(type_indicators)):\n",
    "    print(type_indicators[l])\n",
    "    print(y_test[:,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "IE: Introversion (I) / Extroversion (E) ...\n",
      "(6907, 768) (6907,)\n",
      " Accuracy: 0.772 Precision: 0.772 Recall 0.998 F1-score 0.871 ROC-AUC 0.511\n",
      "\n",
      "\n",
      "NS: Intuition (N) – Sensing (S) ...\n",
      "(6907, 768) (6907,)\n",
      " Accuracy: 0.859 Precision: 0.859 Recall 1.000 F1-score 0.924 ROC-AUC 0.502\n",
      "\n",
      "\n",
      "FT: Feeling (F) - Thinking (T) ...\n",
      "(6907, 768) (6907,)\n",
      " Accuracy: 0.733 Precision: 0.721 Recall 0.680 F1-score 0.700 ROC-AUC 0.729\n",
      "\n",
      "\n",
      "JP: Judging (J) – Perceiving (P) ...\n",
      "(6907, 768) (6907,)\n",
      " Accuracy: 0.658 Precision: 0.647 Recall 0.294 F1-score 0.404 ROC-AUC 0.595\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "    \n",
    "    print(X_train.shape, y_train_class.shape)\n",
    "    seed = 7    \n",
    "    model = XGBClassifier(learning_rate=0.01,\n",
    "                             n_estimators=100,\n",
    "                             max_depth=6,\n",
    "                             min_child_weight=6,\n",
    "                             colsample_bytree=0.7,\n",
    "                             objective='reg:logistic',\n",
    "                             nthread=8,\n",
    "                             scale_pos_weight=1,\n",
    "                             seed=7)\n",
    "\n",
    "    model.fit(X_train, y_train_class)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    prediction_proba = [value for value in y_pred]\n",
    "#     # evaluate predictions\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test_class, predictions)\n",
    "    f1_score_measure = sklearn.metrics.f1_score(y_test_class, predictions)\n",
    "    precision_measure = sklearn.metrics.precision_score(y_test_class, predictions)\n",
    "    recall_measure = sklearn.metrics.recall_score(y_test_class, predictions)\n",
    "    auc_roc = sklearn.metrics.roc_auc_score(y_test_class, predictions)\n",
    "#     mae = sklearn.metrics.mean_absolute_error(y_test_class, prediction_proba)\n",
    "    print(\" Accuracy: {:.3f} Precision: {:.3f} Recall {:.3f} F1-score {:.3f} ROC-AUC {:.3f}\".format(accuracy, \n",
    "                                                                                                    precision_measure, \n",
    "                                                                                                    recall_measure,\n",
    "                                                                                                    f1_score_measure,\n",
    "                                                                                                   auc_roc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, AdaBoostRegressor, AdaBoostClassifier\n",
    "def rmse(y, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred - y)**2))\n",
    "rmse_scorer = sklearn.metrics.make_scorer(rmse, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "IE: Introversion (I) / Extroversion (E) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.4818657043568481 RMSE cv5: {'fit_time': array([2.7370038 , 2.78803873, 2.8469758 , 2.77200437, 2.75600457]), 'score_time': array([0.19800043, 0.19999719, 0.19700074, 0.20200038, 0.19800186]), 'test_acc': array([0.7662037 , 0.76909722, 0.77114716, 0.76940904, 0.76882966]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.76905177, 0.77034884, 0.77169482, 0.77097902, 0.77052999]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.99473288, 0.99699022, 0.99774096, 0.99623494, 0.99623494]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.86745407, 0.86913742, 0.87027915, 0.86925099, 0.86896552]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.49987271, 0.50350764, 0.50640817, 0.50439888, 0.5031426 ]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([3.17906141, 3.2230401 , 3.18802786, 3.18086791, 3.22358561,\n",
      "       3.19604969, 3.18604922, 3.18298912, 3.20500541, 3.16000795]), 'score_time': array([0.11200118, 0.11199975, 0.11200762, 0.11196733, 0.11597562,\n",
      "       0.11199403, 0.11400056, 0.11099982, 0.11202908, 0.10999918]), 'test_acc': array([0.77109827, 0.76416185, 0.76940904, 0.76593279, 0.77172654,\n",
      "       0.77172654, 0.76709154, 0.76825029, 0.77288528, 0.77172654]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.77246208, 0.76771196, 0.77129522, 0.76985981, 0.77119628,\n",
      "       0.77182771, 0.77076023, 0.77294118, 0.77272727, 0.77309942]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.99548872, 0.99398496, 0.99548193, 0.99246988, 1.        ,\n",
      "       0.99849398, 0.99246988, 0.98945783, 0.99849398, 0.99548193]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.86990802, 0.86631717, 0.86916502, 0.86710526, 0.87081967,\n",
      "       0.87065003, 0.8676761 , 0.8678996 , 0.87122208, 0.87030941]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.51024436, 0.49699248, 0.50527865, 0.50126007, 0.50502513,\n",
      "       0.50678468, 0.50377263, 0.50980429, 0.50929724, 0.51030378]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "NS: Intuition (N) – Sensing (S) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.37664904741925176 RMSE cv5: {'fit_time': array([2.99201012, 2.999017  , 3.00058651, 2.95350266, 3.05906844]), 'score_time': array([0.19499993, 0.18999815, 0.19700241, 0.19000626, 0.19300008]), 'test_acc': array([0.86168981, 0.86284722, 0.8626883 , 0.8626883 , 0.86326767]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.8626087 , 0.86276781, 0.8626883 , 0.8626883 , 0.86318841]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.99865772, 1.        , 1.        , 1.        , 1.        ]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.92566096, 0.92632888, 0.92628305, 0.92628305, 0.92657125]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.5014297 , 0.50210084, 0.5       , 0.5       , 0.5021097 ]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([3.62459683, 3.4539957 , 3.46153355, 3.42900872, 3.38912749,\n",
      "       3.43110037, 3.47829413, 3.48104787, 3.46063042, 3.4557519 ]), 'score_time': array([0.11199856, 0.11000276, 0.11800003, 0.11300063, 0.11888981,\n",
      "       0.1230638 , 0.10800028, 0.11199975, 0.11000085, 0.11100149]), 'test_acc': array([0.86111111, 0.86226852, 0.86342593, 0.86342593, 0.86226852,\n",
      "       0.86226852, 0.86226852, 0.86194896, 0.86310905, 0.86310905]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.86210892, 0.86310905, 0.86326767, 0.86326767, 0.86226852,\n",
      "       0.86226852, 0.86226852, 0.86295006, 0.86310905, 0.86310905]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.99865772, 0.99865772, 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99865591, 1.        , 1.        ]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.92537313, 0.92594897, 0.92661692, 0.92661692, 0.92604102,\n",
      "       0.92604102, 0.92604102, 0.9258567 , 0.92652553, 0.92652553]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.49932886, 0.50353054, 0.50420168, 0.50420168, 0.5       ,\n",
      "       0.5       , 0.5       , 0.49932796, 0.5       , 0.5       ]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "FT: Feeling (F) - Thinking (T) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5149755027032662 RMSE cv5: {'fit_time': array([2.73703718, 2.75755143, 2.70211577, 2.72013116, 2.73901129]), 'score_time': array([0.2050004 , 0.19800043, 0.19400883, 0.19300818, 0.20100856]), 'test_acc': array([0.7417487 , 0.74348581, 0.72379849, 0.73306312, 0.72769409]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.75820896, 0.75035868, 0.73613193, 0.73146853, 0.7261236 ]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.64141414, 0.66035354, 0.61994949, 0.66035354, 0.65277778]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.69493844, 0.70248489, 0.67306374, 0.69409423, 0.6875    ]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.73407605, 0.73712864, 0.7158571 , 0.72750297, 0.72199917]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([3.14920545, 3.09414816, 3.10912251, 3.13678837, 3.10615206,\n",
      "       3.14114881, 3.1839056 , 3.07811737, 3.13014674, 3.08211732]), 'score_time': array([0.11100411, 0.11200476, 0.11099601, 0.11299825, 0.11300635,\n",
      "       0.11300468, 0.11300468, 0.11400437, 0.11300588, 0.11297345]), 'test_acc': array([0.74074074, 0.74074074, 0.72106481, 0.74537037, 0.72769409,\n",
      "       0.73696408, 0.73580533, 0.75086906, 0.7230591 , 0.69988413]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.74157303, 0.77922078, 0.71830986, 0.77160494, 0.73607038,\n",
      "       0.75074184, 0.74137931, 0.76080692, 0.73716012, 0.67430025]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.66666667, 0.60606061, 0.64393939, 0.63131313, 0.63383838,\n",
      "       0.63888889, 0.65151515, 0.66666667, 0.61616162, 0.66919192]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.70212766, 0.68181818, 0.67909454, 0.69444444, 0.68113976,\n",
      "       0.69031378, 0.69354839, 0.71063257, 0.67125172, 0.67173638]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.73504274, 0.73038073, 0.71513209, 0.73659674, 0.72055945,\n",
      "       0.72950868, 0.72939783, 0.74446824, 0.71493306, 0.69755099]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "JP: Judging (J) – Perceiving (P) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5869651466497705 RMSE cv5: {'fit_time': array([2.89010787, 2.96111226, 2.96511197, 2.9791441 , 2.94711351]), 'score_time': array([0.20400739, 0.21000981, 0.21000957, 0.20500803, 0.20700741]), 'test_acc': array([0.63020833, 0.63136574, 0.64020857, 0.62746234, 0.62746234]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.59493671, 0.58935361, 0.63716814, 0.57751938, 0.57936508]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.20614035, 0.22660819, 0.21083455, 0.2181552 , 0.21376281]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.30618893, 0.32734952, 0.31683168, 0.31668438, 0.31229947]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.55709316, 0.56157996, 0.56610759, 0.55682448, 0.55606645]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([3.40012717, 3.40512967, 3.4321599 , 3.42512822, 3.38812113,\n",
      "       3.42012978, 3.37216806, 3.34912443, 3.36713052, 3.40309596]), 'score_time': array([0.11800408, 0.1210053 , 0.11800504, 0.12100482, 0.11900496,\n",
      "       0.11700845, 0.11700439, 0.11700606, 0.11600113, 0.11600447]), 'test_acc': array([0.61226852, 0.60532407, 0.62384259, 0.63310185, 0.63657407,\n",
      "       0.65162037, 0.63425926, 0.61716937, 0.61600928, 0.63457077]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.52713178, 0.50406504, 0.56115108, 0.5984252 , 0.6147541 ,\n",
      "       0.68141593, 0.60833333, 0.53793103, 0.54032258, 0.60483871]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.19883041, 0.18128655, 0.22807018, 0.22222222, 0.21929825,\n",
      "       0.2251462 , 0.21345029, 0.228739  , 0.19648094, 0.21994135]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.28874735, 0.26666667, 0.32432432, 0.32409382, 0.32327586,\n",
      "       0.33846154, 0.31601732, 0.32098765, 0.28817204, 0.32258065]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.54098609, 0.53221416, 0.55560597, 0.56226054, 0.56462997,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.57809034, 0.56170599, 0.55007008, 0.54353797, 0.56294572]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "    \n",
    "    print(X_train.shape, y_train_class.shape)\n",
    "    seed = 7    \n",
    "    \n",
    "    model = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "    model.fit(X_train, y_train_class)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "#     # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test_class, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test_class, predictions)\n",
    "    rmse_val = rmse(y_test_class, predictions)\n",
    "    scoring = {'acc': 'accuracy',\n",
    "               'prec':  sklearn.metrics.make_scorer(sklearn.metrics.precision_score),\n",
    "               'rec':  sklearn.metrics.make_scorer(sklearn.metrics.recall_score),\n",
    "               'f1': sklearn.metrics.make_scorer(sklearn.metrics.f1_score),\n",
    "               'roc_auc': sklearn.metrics.make_scorer(sklearn.metrics.roc_auc_score)}\n",
    "    rmse_cv_5 = cross_validate(model, np.array(list_posts_vec), np.array(list_personality_vec)[:,l], cv=5, scoring=scoring)\n",
    "    rmse_cv_10 = cross_validate(model,np.array(list_posts_vec), np.array(list_personality_vec)[:,l], cv=10, scoring=scoring)\n",
    "    print(\" RMSE test: {} RMSE cv5: {} RMSE cv10: {}\".format(rmse_val, rmse_cv_5, rmse_cv_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "IE: Introversion (I) / Extroversion (E) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5869651466497705 RMSE cv5: {'fit_time': array([1.44006062, 1.45605421, 1.48805714, 1.45205045, 1.44208717]), 'score_time': array([0.10299778, 0.10504627, 0.11200929, 0.10200191, 0.10300708]), 'test_acc': array([0.76851852, 0.76851852, 0.76535342, 0.76651217, 0.76651217]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.62274029, 0.62534744, 0.57968408, 0.58981318, 0.58144196]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.50751597, 0.50926979, 0.50792176, 0.507795  , 0.50603545]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.86833443, 0.86816084, 0.86602713, 0.86686488, 0.86704058]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.50751597, 0.50926979, 0.50792176, 0.507795  , 0.50603545]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([1.67306638, 1.68106914, 1.63505435, 1.65805459, 1.71406245,\n",
      "       1.6320591 , 1.6560626 , 1.73009634, 1.65610957, 1.66605735]), 'score_time': array([0.05900288, 0.05799603, 0.05800223, 0.05800223, 0.05900335,\n",
      "       0.05900407, 0.05900025, 0.0599997 , 0.05795312, 0.05900335]), 'test_acc': array([0.7699422 , 0.7699422 , 0.76825029, 0.7636153 , 0.76477404,\n",
      "       0.77867903, 0.77172654, 0.7589803 , 0.76477404, 0.76825029]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.66387591, 0.65914413, 0.6080536 , 0.38403263, 0.58083498,\n",
      "       0.78213865, 0.69904971, 0.51665004, 0.50979532, 0.61342296]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.50949248, 0.5112406 , 0.50628519, 0.49623494, 0.50930481,\n",
      "       0.52537915, 0.51030378, 0.50202065, 0.50050705, 0.50804474]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.86916502, 0.86899276, 0.86824769, 0.86596583, 0.86547382,\n",
      "       0.87376074, 0.87030941, 0.86206897, 0.86635945, 0.86807388]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.50949248, 0.5112406 , 0.50628519, 0.49623494, 0.50930481,\n",
      "       0.52537915, 0.51030378, 0.50202065, 0.50050705, 0.50804474]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "NS: Intuition (N) – Sensing (S) ...\n",
      "(6907, 768) (6907,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE test: 0.5869651466497705 RMSE cv5: {'fit_time': array([1.60805535, 1.53105664, 1.52014256, 1.64306164, 1.61606169]), 'score_time': array([0.09900784, 0.09900475, 0.09900403, 0.10800672, 0.10500669]), 'test_acc': array([0.86111111, 0.86284722, 0.86384705, 0.86326767, 0.86095017]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.5562645 , 0.73180499, 0.93184455, 0.76513832, 0.43122461]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.50109413, 0.50563138, 0.50421941, 0.50388361, 0.49899261]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.9253267 , 0.92623716, 0.92685963, 0.92652553, 0.9252802 ]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.50109413, 0.50563138, 0.50421941, 0.50388361, 0.49899261]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([1.87607074, 1.82407498, 1.81610847, 1.80806303, 1.8450706 ,\n",
      "       1.85707474, 1.81606841, 1.82207131, 1.82006431, 1.81707144]), 'score_time': array([0.06400299, 0.05699372, 0.05800056, 0.05800033, 0.06199932,\n",
      "       0.06199574, 0.05900431, 0.05799961, 0.05800676, 0.05899882]), 'test_acc': array([0.86226852, 0.8587963 , 0.86574074, 0.86226852, 0.86226852,\n",
      "       0.86226852, 0.86226852, 0.86426914, 0.86194896, 0.86078886]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.43113426, 0.43089431, 0.93263647, 0.68155452, 0.43113426,\n",
      "       0.43113426, 0.68155452, 0.93205575, 0.43147503, 0.43139535]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.5       , 0.49798658, 0.51260504, 0.50353054, 0.5       ,\n",
      "       0.5       , 0.50353054, 0.50423729, 0.49932796, 0.49865591]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.92604102, 0.92403487, 0.92777086, 0.92594897, 0.92604102,\n",
      "       0.92604102, 0.92594897, 0.9271028 , 0.9258567 , 0.92518703]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.5       , 0.49798658, 0.51260504, 0.50353054, 0.5       ,\n",
      "       0.5       , 0.50353054, 0.50423729, 0.49932796, 0.49865591]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "FT: Feeling (F) - Thinking (T) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5869651466497705 RMSE cv5: {'fit_time': array([1.45505762, 1.48208642, 1.45702696, 1.47905445, 1.46605206]), 'score_time': array([0.10299873, 0.10500288, 0.10700607, 0.1070056 , 0.10400462]), 'test_acc': array([0.71627099, 0.73190504, 0.72785177, 0.72669369, 0.71320973]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.71741032, 0.73182387, 0.73292486, 0.72744269, 0.71225552]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.70880867, 0.72614379, 0.71853832, 0.7199792 , 0.70775204]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.66666667, 0.69194943, 0.67132867, 0.6819407 , 0.67240238]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.70880867, 0.72614379, 0.71853832, 0.7199792 , 0.70775204]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([1.68306422, 1.68409395, 1.67006135, 1.67406726, 1.7120645 ,\n",
      "       1.6880908 , 1.67506146, 1.69706511, 1.66506267, 1.66106272]), 'score_time': array([0.06200385, 0.0590024 , 0.06000853, 0.05999684, 0.06200385,\n",
      "       0.06000257, 0.06000185, 0.05900097, 0.05900192, 0.05900264]), 'test_acc': array([0.72453704, 0.73032407, 0.7349537 , 0.74421296, 0.71378911,\n",
      "       0.71958285, 0.7161066 , 0.74507532, 0.72421784, 0.68829664]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.72338534, 0.73726764, 0.73362072, 0.74732669, 0.71652631,\n",
      "       0.72591145, 0.71999977, 0.74633969, 0.73007669, 0.68606936]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.71969697, 0.7201826 , 0.73086636, 0.73649961, 0.70521597,\n",
      "       0.70941752, 0.70697337, 0.73873099, 0.71446802, 0.68434884]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.68766404, 0.67043847, 0.70221066, 0.69767442, 0.65836791,\n",
      "       0.6572238 , 0.65829847, 0.70430108, 0.66478873, 0.65200517]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.71969697, 0.7201826 , 0.73086636, 0.73649961, 0.70521597,\n",
      "       0.70941752, 0.70697337, 0.73873099, 0.71446802, 0.68434884]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "\n",
      "JP: Judging (J) – Perceiving (P) ...\n",
      "(6907, 768) (6907,)\n",
      " RMSE test: 0.5869651466497705 RMSE cv5: {'fit_time': array([1.60309052, 1.57305765, 1.58305883, 1.59709215, 1.59306335]), 'score_time': array([0.11100507, 0.11000609, 0.10900784, 0.11000609, 0.11000443]), 'test_acc': array([0.6255787 , 0.6255787 , 0.63615295, 0.62977984, 0.62804171]), 'train_acc': array([1., 1., 1., 1., 1.]), 'test_prec': array([0.60150834, 0.60225226, 0.62260848, 0.61053147, 0.60466574]), 'train_prec': array([1., 1., 1., 1., 1.]), 'test_rec': array([0.55779895, 0.55653862, 0.56704742, 0.5602581 , 0.56235743]), 'train_rec': array([1., 1., 1., 1., 1.]), 'test_f1': array([0.32953368, 0.32251309, 0.33894737, 0.32665964, 0.34489796]), 'train_f1': array([1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.55779895, 0.55653862, 0.56704742, 0.5602581 , 0.56235743]), 'train_roc_auc': array([1., 1., 1., 1., 1.])} RMSE cv10: {'fit_time': array([1.82206988, 1.86306977, 1.81006789, 1.80006242, 1.80206919,\n",
      "       1.81807399, 1.83206868, 1.8330698 , 1.87206602, 1.79206777]), 'score_time': array([0.06400204, 0.06500483, 0.06200171, 0.06200337, 0.06299901,\n",
      "       0.06400323, 0.06400347, 0.06400371, 0.06300282, 0.06200218]), 'test_acc': array([0.62847222, 0.62731481, 0.62268519, 0.625     , 0.63657407,\n",
      "       0.63310185, 0.62037037, 0.64269142, 0.63109049, 0.63805104]), 'train_acc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_prec': array([0.60744084, 0.60388446, 0.59529412, 0.5982906 , 0.62406855,\n",
      "       0.62131295, 0.59235617, 0.63005356, 0.61156054, 0.62557441]), 'train_prec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_rec': array([0.55994152, 0.5610002 , 0.55716878, 0.56261343, 0.56715064,\n",
      "       0.560244  , 0.55122   , 0.5777689 , 0.56310614, 0.56937088]), 'train_rec': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_f1': array([0.32985386, 0.34016393, 0.33739837, 0.35714286, 0.33755274,\n",
      "       0.31236443, 0.31380753, 0.37142857, 0.3375    , 0.34453782]), 'train_f1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_roc_auc': array([0.55994152, 0.5610002 , 0.55716878, 0.56261343, 0.56715064,\n",
      "       0.560244  , 0.55122   , 0.5777689 , 0.56310614, 0.56937088]), 'train_roc_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "    \n",
    "    print(X_train.shape, y_train_class.shape)\n",
    "    seed = 7    \n",
    "    \n",
    "    model = AdaBoostClassifier(ExtraTreesClassifier(n_estimators=50), \n",
    "                              n_estimators=50, \n",
    "                              learning_rate =0.1, \n",
    "                              random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train_class)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "#     # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test_class, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test_class, predictions)\n",
    "    scoring = {'acc': 'accuracy',\n",
    "               'prec': 'precision_macro',\n",
    "               'rec': 'recall_macro',\n",
    "               'f1': sklearn.metrics.make_scorer(sklearn.metrics.f1_score),\n",
    "               'roc_auc': sklearn.metrics.make_scorer(sklearn.metrics.roc_auc_score)}\n",
    "    rmse_cv_5 = cross_validate(model, np.array(list_posts_vec), np.array(list_personality_vec)[:,l], cv=5, scoring=scoring)\n",
    "    rmse_cv_10 = cross_validate(model,np.array(list_posts_vec), np.array(list_personality_vec)[:,l], cv=10, scoring=scoring)\n",
    "    print(\" RMSE test: {} RMSE cv5: {} RMSE cv10: {}\".format(rmse_val, rmse_cv_5, rmse_cv_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "IE: Introversion (I) / Extroversion (E) ...\n",
      "\n",
      "\n",
      "NS: Intuition (N) – Sensing (S) ...\n",
      "\n",
      "\n",
      "FT: Feeling (F) - Thinking (T) ...\n",
      "\n",
      "\n",
      "JP: Judging (J) – Perceiving (P) ...\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Posts in tf-idf representation\n",
    "\n",
    "# Let's train type indicator individually\n",
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    # Let's train type indicator individually\n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "\n",
    "    # split data into train and test sets\n",
    "    model = svm.LinearSVR(C=10)\n",
    "\n",
    "    clf = model.fit(X_train, y_train_class)\n",
    "    \n",
    "#     pca = PCA(n_components=2).fit(X_train_seq_trunc)\n",
    "    \n",
    "#     pca_2d = pca.transform(X_train_seq_trunc)\n",
    "    \n",
    "#     svmClassifier_2d =   svm.LinearSVC(C=10,\n",
    "#                           class_weight='balanced').fit(   pca_2d, y_train_class)\n",
    "    \n",
    "#     for i in range(0, pca_2d.shape[0]):\n",
    "#         if y_train_res[i] == 0:\n",
    "#             c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='r', s=50,marker='+')\n",
    "#         elif y_train_res[i] == 1:\n",
    "#             c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g',    s=50,marker='o')\n",
    "    \n",
    "#     pl.legend([c1, c2], [type_indicators[l][0], type_indicators[l][1]])\n",
    "#     x_min, x_max = pca_2d[:, 0].min() - 1,   pca_2d[:,0].max() + 1\n",
    "#     y_min, y_max = pca_2d[:, 1].min() - 1,   pca_2d[:, 1].max() + 1\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, .01),   np.arange(y_min, y_max, .01))\n",
    "#     Z = svmClassifier_2d.predict(np.c_[xx.ravel(),  yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     pl.contour(xx, yy, Z)\n",
    "#     pl.title('Support Vector Machine Decision Surface')\n",
    "#     pl.axis('off')\n",
    "#     pl.show()\n",
    "    \n",
    "    # make predictions  for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test, predictions)\n",
    "    rmse_val = rmse(y_test_class, predictions)\n",
    "    mae = sklearn.metrics.mean_absolute_error(y_test_class, predictions)\n",
    "    print(\" RMSE: {:.3f} MAE: {:.3f}\".format(rmse_val, mae))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
