{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT \n",
    "https://colab.research.google.com/drive/1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU#scrollTo=E_t4cM6KLc98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# * File:    Twitter_Persona_GloVe.py\n",
    "# *\n",
    "# * Author1:  Pavan Kumar K N (pavankumar.karkekopp@ucalgary.ca)\n",
    "# * Date:     11th Aug 2019\n",
    "# * Summary of File:\n",
    "# * Explore mbti_1.csv file acquired from https://www.kaggle.com/datasnaek/mbti-type\n",
    "# * Apply state-of-the-art reported publicly\n",
    "# * Build classifier model that is better using machine learning techniques\n",
    "\n",
    "#Just making sure the right environment is running this script\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# # Load pre-trained model tokenizer (vocabulary)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Here is the sentence I want embeddings for.\"\n",
    "# text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# print (marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_text = tokenizer.tokenize(marked_text)\n",
    "# print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# for tup in zip(tokenized_text, indexed_tokens):\n",
    "#     print (tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments_ids = [1] * len(tokenized_text)\n",
    "# print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert inputs to PyTorch tensors\n",
    "# tokens_tensor = torch.tensor([indexed_tokens])\n",
    "# segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# # Load pre-trained model (weights)\n",
    "# model = BertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict hidden states features for each layer\n",
    "# with torch.no_grad():\n",
    "#     encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Number of layers:\", len(encoded_layers))\n",
    "# layer_i = 0\n",
    "\n",
    "# print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "# batch_i = 0\n",
    "\n",
    "# print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "# token_i = 0\n",
    "\n",
    "# print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the 5th token in our sentence, select its feature values from layer 5.\n",
    "# token_i = 5\n",
    "# layer_i = 5\n",
    "# vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "# # Plot the values as a histogram to show their distribution.\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.hist(vec, bins=200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the hidden state embeddings into single token vectors\n",
    "\n",
    "# # Holds the list of 12 layer embeddings for each token\n",
    "# # Will have the shape: [# tokens, # layers, # features]\n",
    "# token_embeddings = [] \n",
    "\n",
    "# # For each token in the sentence...\n",
    "# for token_i in range(len(tokenized_text)):\n",
    "#     # Holds 12 layers of hidden states for each token \n",
    "#     hidden_layers = [] \n",
    "#     # For each of the 12 layers...\n",
    "#     for layer_i in range(len(encoded_layers)):\n",
    "\n",
    "#         # Lookup the vector for `token_i` in `layer_i`\n",
    "#         vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "#         hidden_layers.append(vec)\n",
    "\n",
    "#     token_embeddings.append(hidden_layers)\n",
    "\n",
    "# # Sanity check the dimensions:\n",
    "# print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
    "# print (\"Number of layers per token:\", len(token_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Stores the token vectors, with shape [22 x 3,072]\n",
    "# token_vecs_cat = []\n",
    "\n",
    "# # For each token in the sentence...\n",
    "# for token in token_embeddings:\n",
    "#     # Concatenate the vectors (that is, append them together) from the last \n",
    "#     # four layers.\n",
    "#     # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "#     cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), 0)\n",
    "    \n",
    "#     # Use `cat_vec` to represent `token`.\n",
    "#     token_vecs_cat.append(cat_vec)\n",
    "\n",
    "# print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stores the token vectors, with shape [22 x 768]\n",
    "# token_vecs_sum = []\n",
    "\n",
    "# # For each token in the sentence...\n",
    "# for token in token_embeddings:\n",
    "#     # Sum the vectors from the last four layers.\n",
    "#     sum_vec = torch.sum(torch.stack(token)[-4:], 0)\n",
    "    \n",
    "#     # Use `sum_vec` to represent `token`.\n",
    "#     token_vecs_sum.append(sum_vec)\n",
    "\n",
    "# print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_embedding = torch.mean(encoded_layers[11], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,x in enumerate(tokenized_text):\n",
    "#     print (i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"First fifteen values of 'bank' as in 'bank robber':\")\n",
    "# token_vecs_sum[10][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"First fifteen values of 'bank' as in 'bank vault':\")\n",
    "# token_vecs_sum[6][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"First fifteen values of 'bank' as in 'river bank':\")\n",
    "# token_vecs_sum[19][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"river bank\"\n",
    "# different_bank = cosine_similarity(token_vecs_sum[10].reshape(1,-1), token_vecs_sum[19].reshape(1,-1))[0][0]\n",
    "\n",
    "# # Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"bank vault\" \n",
    "# same_bank = cosine_similarity(token_vecs_sum[10].reshape(1,-1), token_vecs_sum[6].reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'bank vault':\",  same_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'river bank':\",  different_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Read Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert from XML to Twitter MBTI dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import requests \n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePAN(directory_with_xmls): \n",
    "    # Initialize for Lemmatization\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "    directory_with_xmls = Path(directory_with_xmls)\n",
    "    truth_filepath =  directory_with_xmls / \"truth.txt\"\n",
    "    personality_traits_dict = {}\n",
    "    with open(truth_filepath) as truth_file:\n",
    "        for line in truth_file:\n",
    "            (user_id, gender, age_group, extroverted, stable, agreeable, \n",
    "                                         conscientious, openness) =  line.split(':::')\n",
    "            personality_traits_dict[user_id] = [[], float(openness), float(conscientious), \n",
    "                                                float(extroverted), float(agreeable), float(stable)]\n",
    "    \n",
    "    list_posts = []\n",
    "    list_personality = []\n",
    "\n",
    "    for xmlfile in directory_with_xmls.glob('**/*.xml'):\n",
    "        \n",
    "        # create element tree object \n",
    "        tree = ET.parse(xmlfile) \n",
    "\n",
    "        # get root element \n",
    "        root = tree.getroot() \n",
    "\n",
    "        user_id = root.attrib['id']\n",
    "\n",
    "        # create empty list for news tweets \n",
    "        tweets = []\n",
    "        \n",
    "\n",
    "        # iterate news items \n",
    "        for item in root.findall('document'):\n",
    "            tweet_string = item.text\n",
    "\n",
    "            #Removing mentions\n",
    "            tweet_string = tweet_string.replace('@username', '')\n",
    "            #Removing unecessary spaces\n",
    "            \n",
    "            #Removing URL\n",
    "            tweet_string = re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", tweet_string)\n",
    "            tweet_string = tweet_string.strip()\n",
    "            tweets.append(tweet_string)\n",
    "            \n",
    "            j=0\n",
    "            for pos in tweets:\n",
    "                pos = re.sub(\"[^a-zA-Z]\", \" \", pos)\n",
    "                pos = re.sub(\" +\", \" \", pos).lower()\n",
    "                pos = \" \".join([lemmatiser.lemmatize(w) for w in pos.split(' ')])\n",
    "                \n",
    "                if pos!= \" \":\n",
    "                    tweets[j] = pos\n",
    "                else:\n",
    "                    tweets[j] = None\n",
    "\n",
    "                j += 1\n",
    "            \n",
    "        tweets = list(filter(None, tweets))\n",
    "        \n",
    "        #'Add [SEP] tokens for BERT tokenizer'\n",
    "        processed_tweets = '[SEP]'.join(tweets)\n",
    "        list_posts.append(processed_tweets)\n",
    "        list_personality.append(np.array(personality_traits_dict[user_id][1:]))\n",
    "    return np.array(list_posts), np.array(list_personality)\n",
    "\n",
    "def annotatePersonality(xmlfile):\n",
    "    truth_filepath = Path(xmlfile).parents[0] / \"truth.txt\"\n",
    "    truth_file = open(truth_filepath)\n",
    "    return personality_profile\n",
    "  \n",
    "def savetoCSV(newsitems, filename): \n",
    "  \n",
    "    # specifying the fields for csv file \n",
    "    fields = ['guid', 'title', 'pubDate', 'description', 'link', 'media'] \n",
    "  \n",
    "    # writing to csv file \n",
    "    with open(filename, 'w') as csvfile: \n",
    "  \n",
    "        # creating a csv dict writer object \n",
    "        writer = csv.DictWriter(csvfile, fieldnames = fields) \n",
    "  \n",
    "        # writing headers (field names) \n",
    "        writer.writeheader() \n",
    "  \n",
    "        # writing data rows \n",
    "        writer.writerows(newsitems) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posts, list_personality = parsePAN(\"data/pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('thing i want for my business card but are too expensive pm color colored edge soft touch finish raised spot uv cut corner [SEP] painter produced their most highly valued work when they were year old so i ve year left for mine [SEP]your new discussion layout is confusing regarding who say what because the comment aren t sectioned off [SEP]i never really understood why game environment which you see most of get so few resource compared to character [SEP] k and on a gun fine but throwing the same on an enemy that you try to shoot before he get too close [SEP]gun using the texture already in memory is good gun on the floor having the same model a fps isn t probably lod model [SEP]i m talking about char that are small scale compared to enviro prop extreme example tri scene[SEP]dammit crendor you broke jesse s game and made the audio go poof totally your fault [SEP]i liken esther to a movie you can choose to progress or not but not affect much else but really grey area [SEP]gamers unfazed sale ha arrived the tiniest price finest of prize gaben be praised discount shall thrive [SEP]indie gamedev i don t want to be bound by publisher and marketing test indy gamedev game are an artform they belong in a museum [SEP] mbit here get for in the netherlands previous contract since or wa same speed [SEP]on the flipside half game for half price [SEP]happy new year with an appropriately time new site [SEP]just played the first two episode of quake again game s still tight loving the smooth movement [SEP]so apparently paying a month for spotify make me worse than a music pirate dafuq [SEP]wanted to say i appreciate the choice for minion should make the game feel nicely crowded and give bad player more fun [SEP]heh i think it s funny you re apologizing for sound quality that s still better than say of youtube game voiceovers [SEP]i know this is cool and serious science but it had me giggling like a kid best of both world [SEP]working on refining my logo to chamfer or nor to chamfer that is the question [SEP] c to protect and infect youtube i don t know a whole lot about network security but enough that this scare me [SEP]silly spotify white zombie judge dredd soundtrack rob zombie blue man group okay then [SEP]thanks for mentioning the hearthstone open beta i ve been anxiously waiting but hadn t gotten any email about it yet [SEP]do you perchance read jezebel the timing is rather close [SEP]i am so sick of people on twitter complaining about a bunch people on twitter [SEP] help to have a map no no it doesn t [SEP]remember the time you paid grand for celebrity fashion without airbrushing pic so do these people [SEP]steam s down wonder if that s because of the new music stuff [SEP]play this now tomorrow during lunch whenever it s only minute but it s awesome [SEP]first time i bought a key for dota treasure chest baby roshan pretty sweet deal [SEP]hah that shit s golden telltale [SEP]are you still looking for people i can free up some time and be almost completely dedicated the next month s [SEP]i threw up some isometric example at assuming you want to stick with the rpgmaker perspective [SEP]not many developer company would opt out of lot of money because something s addictive i respect you for that [SEP]now that s a proper free to play dungeon keeper [SEP]i like this [SEP]how do they not help i find it very useful to know if a game ha been designed for touchscreen controller or kbm [SEP]remember that fake twitch lol video from this afternoon here s a real twitch play dota channel [SEP]thanks for reminding me u to disable adblock for place i regularly visit because it s often a fairer trade that tv radio [SEP]mini metro quite a novel idea build your own growing metro system not sure about longevity replayability though [SEP]how about keeping the same root word and call them bullvids [SEP]coil because of it several experiment mirror s edge because of it absence and whichever game started radial menu crysis [SEP]consider that a free game thrown in by the god for your generous purchase [SEP] luft mean air not red and rauser probably stem from the dutch verb rouzen playing wildly or razen rage storm [SEP]did you guy just change all your youtube video thumbnail or have i not paid proper attention lately [SEP]do you also know about [SEP]is this april fool or did they really start a website on april st with the plan of confusing people on every anniversary [SEP]whelp wanted drama he got drama can the devs get a nice game jam now since that s what they wanted game jam[SEP]great april fool joke anita sarkeesian receiving gdc ambassador award for making video in two year time [SEP]for a moment i thought i wa reading about a game from[SEP]your avvy is now black red white doe this mean future content will be in betrayer vision [SEP]hey i wanted to inform you that potato dungeon seems to be borked right now clicking to ride pard doesn t work for me anyways [SEP]not fond of new design discrover show le per page and the menu bar show le line so i must scroll to get to my playlist [SEP]it s a carefully planned deal he asked both for the exact same amount so he s raking in cash but staying neutral [SEP]combine any random music term in youtube it probably ha it raprock acapella metal industrial jazz celtic chiptunes gregorian dubstep [SEP]i feel like i can express myself le right now it s all white will there be a way to change style besides just link color [SEP]harold and kumar walk down the aisle because racial inclusivity of course [SEP]just crashed in to more bug in minute on the bike than in the past two week of game development [SEP]goddamnit i hate it when a commenting system force you to first register but meanwhile doesn t save your typed post lookingatu[SEP]is the new ui broken or just badly designed i can no longer sort album or search query by name artist album length rating [SEP]yes but only cool people [SEP]might be cool for portfolio horizontal scrolling single page template also on github html c [SEP]i wonder how many people realized what horrible thing they sometimes say good luck best wish and dump that lump [SEP]just rode past some kid biking km for some i guess that s pretty healthy in the end [SEP]if you sit like this and stare past your crotch it probably is but only barely [SEP]here s hoping this will wake people up a bit about greenlight early access kickstarter right [SEP]what you re saying is you re now opening a p o box under the name of cynicalcox [SEP]you hypocrite you closing down your p o box for other company but still accepting bribe from polaris bias bias [SEP]yay mustasch [SEP]jim is in fact a drag king in real life he is an ethereal spirit but for his show he dress up a a man [SEP]the point is not better because harder but balanced against lame exploit it mean you actually think engage with the game [SEP]this should be enough energydrink for at least two day [SEP]bad pixel shirt are one of those thing that annoy and bother me more than they probably should [SEP]so what do we call this kind of review score hate strife out of ten [SEP]good old gaming a store kinda like steam origin but aimed at retro indie more than aaa [SEP]u s healthcare it ll cost you an arm and a leg either way [SEP]get the spambots under control please [SEP]and here s yet another one [SEP]more spammer clean them up [SEP]no but i can reccommend you a great shirt [SEP]turn out you should not attempt to run km barefoot when you haven t done so in three year ouch [SEP]whoa whoa whoa not just a black baseball cap one with a very iconic stitchy liny logo thing [SEP]half life no no carmack made doom quake rage half life is from [SEP]why is there something wrong with them are the ad too silent to hear for you we are not having that issue [SEP]going to try and get something done for lowrezjam day left so it s gonna be tight but i know what i m gonna make a x fighter [SEP]i m not seeing the problem with that lowrezjam workfile look perfectly usable [SEP]a long a everything is in nice sprite strip i m happy for small stuff like this panning around is easier than tab window [SEP]face pulp actually i should probably have scaled up the image p heck i m working small enough to make the game [SEP]i d like to know which devs you consider upstanding trustworthy what with nintendo greed watchdog graphic and [SEP]indie such a town and that recent plane game air control who do you like still [SEP]i just spent an absurd amount of time playing with this remarkable online sid keyboard emulator [SEP]while your point is true you re not the best advocate lot of woman feature their look notallwomen[SEP]the time when your dog want to eat the rotting half corpse of a mouse and you have to pluck it out of her mouth [SEP]hey i wanted to check if you were aware of this pixel pig game using your artwork [SEP]good vid but missing one element presentation host a much content a possible have curated list of the best the new [SEP] the interesting and so on make it easier to navigate empowering critic user not curation but promotion navigation [SEP]wow this wa great i love simple game like these that require very little time complexity to convey a strong idea [SEP]oh no is offline a are the forum sound the alarm sound the alarm [SEP]the concentric pattern make me wonder if dithering could make the layer transition more natural looking [SEP]with facebook in your future doe this mean we might finally get a legitimate desktop version of whatsapp ',\n",
       " array([0.5, 0.1, 0.2, 0.1, 0.2]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_posts[0], list_personality[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "bert_model = BertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "bert_model.eval()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify max_token_length according to above\n",
    "max_token_length = 256\n",
    "list_posts_vec = []\n",
    "\n",
    "\n",
    "for posts in list_posts:\n",
    "    sentence_list = posts.split('[SEP]')\n",
    "    running_token_len = 0\n",
    "    sentence_count = 0\n",
    "    tweet_stream_vec_list = []\n",
    "    text_batch_list = []\n",
    "    text = \"\"\n",
    "    \n",
    "    #Split the sequence of tweets into separate batches of max_token_length\n",
    "    for sentence in sentence_list:\n",
    "        \n",
    "        sentence_len = len(sentence.strip().split(' '))\n",
    "#         print(\" \\Sentence Length: {}\\n  \\nRunning Token Length: {}\".format(sentence_len, running_token_len))\n",
    "        #Case 1: Sentence is smaller than max token_length\n",
    "        if(sentence_len <= max_token_length):\n",
    "           \n",
    "           #Concatenate into single post\n",
    "            if(running_token_len + sentence_len < max_token_length):\n",
    "                running_token_len += sentence_len\n",
    "                text += sentence\n",
    "            \n",
    "            else:\n",
    "                if text!= \"\":\n",
    "                    text_batch_list.append(text)\n",
    "                sentence_count += 1\n",
    "                running_token_len = sentence_len\n",
    "                text = sentence\n",
    "           \n",
    "        \n",
    "        else:\n",
    "            if text!= \"\":\n",
    "                text_batch_list.append(text)\n",
    "            text_len = len(sentence.strip().split(' '))\n",
    "            \n",
    "            while(text_len > max_token_length):\n",
    "                text_batch_list.append( \" \".join(sentence.strip().split(' ')[:max_token_length]))\n",
    "                sentence = \" \".join(sentence.strip().split(' ')[max_token_length:])\n",
    "                text_len = len(sentence.strip().split(' '))\n",
    "            \n",
    "            running_token_len = sentence_len\n",
    "            text = sentence\n",
    "        \n",
    "#     print(\"Total batches: {}\\n{}\".format(len(text_batch_list), [len(text.strip().split(' ')) for text in text_batch_list]))\n",
    "\n",
    "    #Process the batches\n",
    "    for text in text_batch_list:\n",
    "        marked_text = \"[CLS]\" + text + \"[SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#         print(marked_text)\n",
    "#         print((tokenized_text))\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        \n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        \n",
    "#         print(tokens_tensor.shape, segments_tensors.shape)\n",
    "        # Predict hidden states features for each layer\n",
    "        with torch.no_grad():\n",
    "            encoded_layers, _ = bert_model(tokens_tensor, segments_tensors)\n",
    "            \n",
    "        token_embeddings = [] \n",
    "\n",
    "        batch_i = 0 #Since we have only one sentence\n",
    "        # For each token in the sentence...\n",
    "        for token_i in range(len(tokenized_text)):\n",
    "\n",
    "            # Holds 12 layers of hidden states for each token \n",
    "            hidden_layers = [] \n",
    "\n",
    "            # For each of the 12 layers...\n",
    "            for layer_i in range(len(encoded_layers)):\n",
    "\n",
    "                # Lookup the vector for `token_i` in `layer_i`\n",
    "                vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "                hidden_layers.append(vec)\n",
    "\n",
    "        token_embeddings.append(hidden_layers)\n",
    "\n",
    "        # Stores the token vectors, with shape [22 x 768]\n",
    "        token_vecs_sum = []\n",
    "\n",
    "        # For each token in the sentence...\n",
    "        for token in token_embeddings:\n",
    "            # Sum the vectors from the last four layers.\n",
    "            sum_vec = torch.sum(torch.stack(token)[-4:], 0)\n",
    "\n",
    "            # Use `sum_vec` to represent `token`.\n",
    "            token_vecs_sum.append(sum_vec)\n",
    "        \n",
    "        sentence_embedding = torch.mean(encoded_layers[11], 1)\n",
    "        tweet_stream_vec_list.append(sentence_embedding)\n",
    "        \n",
    "    #Concatenate the stream vector into one vector to represent the whole stream\n",
    "    tweet_stream_vec = torch.mean(torch.stack(tweet_stream_vec_list), dim=0)\n",
    "    list_posts_vec.append(tweet_stream_vec.numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14076419,  0.06908125,  0.32789984, ...,  0.17618908,\n",
       "        -0.02870247, -0.14604895],\n",
       "       [-0.14961849,  0.11144754,  0.28566363, ...,  0.15366356,\n",
       "        -0.02715888, -0.16435553],\n",
       "       [ 0.0285301 ,  0.19369738,  0.35931587, ...,  0.19849722,\n",
       "         0.03765696, -0.14152308],\n",
       "       ...,\n",
       "       [-0.12246948,  0.19571012,  0.5556744 , ...,  0.14211492,\n",
       "         0.0790334 , -0.13616519],\n",
       "       [-0.10317525,  0.21361239,  0.46397024, ..., -0.04584052,\n",
       "        -0.10965005,  0.04650858],\n",
       "       [-0.04086985,  0.06126382,  0.4334332 , ...,  0.10920831,\n",
       "         0.01534395, -0.13816547]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list_posts_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(list_posts_vec), np.array(list_personality), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred - y)**2))\n",
    "\n",
    "def deep_model(model, X_train, y_train, X_valid, y_valid):\n",
    "    '''\n",
    "    Function to train a multi-class model. The number of epochs and \n",
    "    batch_size are set by the constants at the top of the\n",
    "    notebook. \n",
    "    \n",
    "    Parameters:\n",
    "        model : model with the chosen architecture\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_valid : validation features\n",
    "        Y_valid : validation target\n",
    "    Output:\n",
    "        model training history\n",
    "    '''\n",
    "    model.compile(optimizer='rmsprop'\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train\n",
    "                       , y_train\n",
    "                       , epochs=NB_START_EPOCHS\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       , verbose=1)\n",
    "    return history\n",
    "\n",
    "\n",
    "def eval_metric(history, metric_name):\n",
    "    '''\n",
    "    Function to evaluate a trained model on a chosen metric. \n",
    "    Training and validation metric are plotted in a\n",
    "    line chart for each epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        history : model training history\n",
    "        metric_name : loss or accuracy\n",
    "    Output:\n",
    "        line chart with epochs of x-axis and metric on\n",
    "        y-axis\n",
    "    '''\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name]\n",
    "\n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n",
    "    '''\n",
    "    Function to test the model on new data after training it\n",
    "    on the full training data with the optimal number of epochs.\n",
    "    \n",
    "    Parameters:\n",
    "        model : trained model\n",
    "        X_train : training features\n",
    "        y_train : training target\n",
    "        X_test : test features\n",
    "        y_test : test target\n",
    "        epochs : optimal number of epochs\n",
    "    Output:\n",
    "        test accuracy and test loss\n",
    "    '''\n",
    "    model.fit(X_train\n",
    "              , y_train\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=BATCH_SIZE\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness\n",
      "[ 0.1  0.2  0.1  0.5  0.1  0.4  0.3  0.1 -0.1  0.3  0.2  0.5  0.2  0.2\n",
      "  0.1  0.2  0.4  0.2  0.3  0.3  0.2  0.1  0.3  0.4  0.2  0.1  0.1  0.5\n",
      "  0.5  0.5  0.5]\n",
      "Conscientiousness\n",
      "[ 0.2  0.1  0.1  0.5  0.2  0.   0.2 -0.1  0.   0.1  0.2  0.   0.3  0.\n",
      "  0.1  0.   0.   0.2  0.3  0.3  0.1  0.1  0.5  0.1  0.2  0.5  0.1  0.4\n",
      "  0.5  0.4  0.5]\n",
      "Exraversion\n",
      "[ 0.3  0.1 -0.1  0.3  0.3  0.2 -0.1  0.   0.3  0.5  0.3 -0.2  0.  -0.1\n",
      "  0.5  0.2  0.1  0.4  0.1  0.1  0.1  0.2  0.1  0.2  0.3  0.1  0.1  0.2\n",
      "  0.   0.2  0.3]\n",
      "Agreeableness\n",
      "[ 0.2  0.3  0.1  0.1  0.2  0.   0.1  0.1 -0.1  0.   0.1 -0.1 -0.3  0.1\n",
      "  0.1  0.2  0.1  0.2  0.   0.   0.   0.2  0.5  0.2  0.1 -0.1 -0.1  0.4\n",
      " -0.2  0.4  0.1]\n",
      "Neuroticism\n",
      "[ 0.2  0.2 -0.1  0.1  0.2  0.5  0.2 -0.1 -0.1  0.3  0.5 -0.3 -0.2  0.2\n",
      "  0.1  0.4  0.4  0.5  0.2  0.2  0.4  0.1  0.4  0.4  0.5  0.1 -0.1  0.2\n",
      "  0.4  0.2  0.1]\n"
     ]
    }
   ],
   "source": [
    "type_indicators = [ \"Openness\", \"Conscientiousness\", \"Exraversion\", \"Agreeableness\", \"Neuroticism\"]\n",
    "\n",
    "for l in range(len(type_indicators)):\n",
    "    print(type_indicators[l])\n",
    "    print(y_test[:,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Openness ...\n",
      "(121, 1024) (121,)\n",
      " RMSE: 0.190 MAE: 0.116\n",
      "\n",
      "\n",
      "Conscientiousness ...\n",
      "(121, 1024) (121,)\n",
      " RMSE: 0.224 MAE: 0.155\n",
      "\n",
      "\n",
      "Exraversion ...\n",
      "(121, 1024) (121,)\n",
      " RMSE: 0.178 MAE: 0.135\n",
      "\n",
      "\n",
      "Agreeableness ...\n",
      "(121, 1024) (121,)\n",
      " RMSE: 0.183 MAE: 0.142\n",
      "\n",
      "\n",
      "Neuroticism ...\n",
      "(121, 1024) (121,)\n",
      " RMSE: 0.286 MAE: 0.197\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "    \n",
    "    print(X_train.shape, y_train_class.shape)\n",
    "    seed = 7    \n",
    "    model = XGBClassifier(learning_rate=0.01,\n",
    "                             n_estimators=100,\n",
    "                             max_depth=6,\n",
    "                             min_child_weight=6,\n",
    "                             colsample_bytree=0.7,\n",
    "                             objective='reg:logistic',\n",
    "                             nthread=8,\n",
    "                             scale_pos_weight=1,\n",
    "                             seed=7)\n",
    "\n",
    "    model.fit(X_train, y_train_class)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [value for value in y_pred]\n",
    "#     # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test_class, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test_class, predictions)\n",
    "    rmse_val = rmse(y_test_class, predictions)\n",
    "    mae = sklearn.metrics.mean_absolute_error(y_test_class, predictions)\n",
    "    print(\" RMSE: {:.3f} MAE: {:.3f}\".format(rmse_val, mae))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, AdaBoostRegressor\n",
    "def rmse(y, y_pred):\n",
    "        return np.sqrt(np.mean((y_pred - y)**2))\n",
    "rmse_scorer = sklearn.metrics.make_scorer(rmse, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Openness ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.147 RMSE cv5: -0.135 RMSE cv10: -0.128\n",
      "\n",
      "\n",
      "Conscientiousness ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.187 RMSE cv5: -0.141 RMSE cv10: -0.139\n",
      "\n",
      "\n",
      "Exraversion ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.138 RMSE cv5: -0.156 RMSE cv10: -0.152\n",
      "\n",
      "\n",
      "Agreeableness ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.168 RMSE cv5: -0.145 RMSE cv10: -0.144\n",
      "\n",
      "\n",
      "Neuroticism ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.184 RMSE cv5: -0.193 RMSE cv10: -0.189\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "    \n",
    "    print(X_train.shape, y_train_class.shape)\n",
    "    seed = 7    \n",
    "    \n",
    "    model = ExtraTreesRegressor(n_estimators=100)\n",
    "\n",
    "    model.fit(X_train, y_train_class)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [value for value in y_pred]\n",
    "#     # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test_class, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test_class, predictions)\n",
    "    rmse_val = rmse(y_test_class, predictions)\n",
    "    rmse_cv_5 = cross_validate(model, np.array(list_posts_vec), np.array(list_personality[:,l]), cv=5, scoring=rmse_scorer)['test_score'].mean()\n",
    "    rmse_cv_10 = cross_validate(model,np.array(list_posts_vec), np.array(list_personality[:,l]), cv=10, scoring=rmse_scorer)['test_score'].mean()\n",
    "    print(\" RMSE test: {:.3f} RMSE cv5: {:.3f} RMSE cv10: {:.3f}\".format(rmse_val, rmse_cv_5, rmse_cv_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Openness ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.144 RMSE cv5: -0.134 RMSE cv10: -0.129\n",
      "\n",
      "\n",
      "Conscientiousness ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.181 RMSE cv5: -0.142 RMSE cv10: -0.139\n",
      "\n",
      "\n",
      "Exraversion ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.142 RMSE cv5: -0.157 RMSE cv10: -0.151\n",
      "\n",
      "\n",
      "Agreeableness ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.168 RMSE cv5: -0.144 RMSE cv10: -0.143\n",
      "\n",
      "\n",
      "Neuroticism ...\n",
      "(121, 1024) (121,)\n",
      " RMSE test: 0.185 RMSE cv5: -0.191 RMSE cv10: -0.188\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "    \n",
    "    print(X_train.shape, y_train_class.shape)\n",
    "    seed = 7    \n",
    "    \n",
    "    model = AdaBoostRegressor(ExtraTreesRegressor(n_estimators=50), \n",
    "                              n_estimators=50, \n",
    "                              learning_rate =0.1, \n",
    "                              loss='square', \n",
    "                              random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train_class)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [value for value in y_pred]\n",
    "#     # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test_class, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test_class, predictions)\n",
    "    rmse_val = rmse(y_test_class, predictions)\n",
    "    rmse_cv_5 = cross_validate(model, np.array(list_posts_vec), np.array(list_personality[:,l]), cv=5, scoring=rmse_scorer)['test_score'].mean()\n",
    "    rmse_cv_10 = cross_validate(model,np.array(list_posts_vec), np.array(list_personality[:,l]), cv=10, scoring=rmse_scorer)['test_score'].mean()\n",
    "    print(\" RMSE test: {:.3f} RMSE cv5: {:.3f} RMSE cv10: {:.3f}\".format(rmse_val, rmse_cv_5, rmse_cv_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Openness ...\n",
      "\n",
      "\n",
      "Conscientiousness ...\n",
      "\n",
      "\n",
      "Exraversion ...\n",
      "\n",
      "\n",
      "Agreeableness ...\n",
      "\n",
      "\n",
      "Neuroticism ...\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Openness ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE: 0.195 MAE: 0.166\n",
      "\n",
      "\n",
      "Conscientiousness ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE: 0.178 MAE: 0.134\n",
      "\n",
      "\n",
      "Exraversion ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE: 0.143 MAE: 0.118\n",
      "\n",
      "\n",
      "Agreeableness ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE: 0.195 MAE: 0.155\n",
      "\n",
      "\n",
      "Neuroticism ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE: 0.191 MAE: 0.155\n"
     ]
    }
   ],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Posts in tf-idf representation\n",
    "\n",
    "# Let's train type indicator individually\n",
    "for l in range(len(type_indicators)):\n",
    "    print(\"\\n\\n{} ...\".format(type_indicators[l]))\n",
    "    \n",
    "    # Let's train type indicator individually\n",
    "    y_train_class = y_train[:,l]\n",
    "    y_test_class = y_test[:,l]\n",
    "\n",
    "    # split data into train and test sets\n",
    "    model = svm.LinearSVR(C=10)\n",
    "\n",
    "    clf = model.fit(X_train, y_train_class)\n",
    "    \n",
    "#     pca = PCA(n_components=2).fit(X_train_seq_trunc)\n",
    "    \n",
    "#     pca_2d = pca.transform(X_train_seq_trunc)\n",
    "    \n",
    "#     svmClassifier_2d =   svm.LinearSVC(C=10,\n",
    "#                           class_weight='balanced').fit(   pca_2d, y_train_class)\n",
    "    \n",
    "#     for i in range(0, pca_2d.shape[0]):\n",
    "#         if y_train_res[i] == 0:\n",
    "#             c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='r', s=50,marker='+')\n",
    "#         elif y_train_res[i] == 1:\n",
    "#             c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g',    s=50,marker='o')\n",
    "    \n",
    "#     pl.legend([c1, c2], [type_indicators[l][0], type_indicators[l][1]])\n",
    "#     x_min, x_max = pca_2d[:, 0].min() - 1,   pca_2d[:,0].max() + 1\n",
    "#     y_min, y_max = pca_2d[:, 1].min() - 1,   pca_2d[:, 1].max() + 1\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, .01),   np.arange(y_min, y_max, .01))\n",
    "#     Z = svmClassifier_2d.predict(np.c_[xx.ravel(),  yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     pl.contour(xx, yy, Z)\n",
    "#     pl.title('Support Vector Machine Decision Surface')\n",
    "#     pl.axis('off')\n",
    "#     pl.show()\n",
    "    \n",
    "    # make predictions  for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [value for value in y_pred]\n",
    "    # evaluate predictions\n",
    "#     accuracy = sklearn.metrics.accuracy_score(y_test, predictions)\n",
    "#     f1_score_measure = sklearn.metrics.f1_score(y_test, predictions)\n",
    "    rmse_val = rmse(y_test_class, predictions)\n",
    "    mae = sklearn.metrics.mean_absolute_error(y_test_class, predictions)\n",
    "    print(\" RMSE: {:.3f} MAE: {:.3f}\".format(rmse_val, mae))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
